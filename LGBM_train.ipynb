{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e303bb0-8a49-455b-b3a3-1d4c6100b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning) \n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    message=\"X does not have valid feature names, but LGBMRegressor was fitted with feature names\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fceb571-d9f5-425d-8fa3-04704cad0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, PowerTransformer\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    RBF,\n",
    "    Matern,\n",
    "    RationalQuadratic,\n",
    "    ExpSineSquared,\n",
    "    DotProduct,\n",
    "    WhiteKernel,\n",
    "    ConstantKernel\n",
    ")\n",
    "\n",
    "import os\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from optuna.exceptions import TrialPruned\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dadf5395-13fc-4c01-8a37-b09f88ecca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_volume_weighted_component_features(X):\n",
    "    \"\"\"\n",
    "    Computes individual volume-weighted features WjPk = Componentj_fraction * Componentj_Propertyk\n",
    "    for j in 1..5 and k in 1..10 (total 50 features).\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for comp_idx in range(1, 6):  # Components 1–5\n",
    "        for prop_idx in range(1, 11):  # Properties 1–10\n",
    "            vol_col = f'Component{comp_idx}_fraction'\n",
    "            prop_col = f'Component{comp_idx}_Property{prop_idx}'\n",
    "            feat_name = f'W{comp_idx}P{prop_idx}'\n",
    "            features[feat_name] = X[vol_col] * X[prop_col]\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c88498-9201-4af8-b9e1-4813a3c30210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import os\n",
    "\n",
    "def clip_outliers_iqr(df, factor=1.5):\n",
    "    clipped_df = df.copy()\n",
    "    clip_info = {}\n",
    "    \n",
    "    for col in clipped_df.select_dtypes(include=np.number).columns:\n",
    "        Q1 = clipped_df[col].quantile(0.25)\n",
    "        Q3 = clipped_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - factor * IQR\n",
    "        upper = Q3 + factor * IQR\n",
    "\n",
    "        before = clipped_df[col].copy()\n",
    "        clipped_df[col] = clipped_df[col].clip(lower, upper)\n",
    "\n",
    "        n_clipped = (before != clipped_df[col]).sum()\n",
    "        if n_clipped > 0:\n",
    "            clip_info[col] = n_clipped\n",
    "\n",
    "    return clipped_df, clip_info\n",
    "\n",
    "def apply_quantile_transform(df):\n",
    "    df_transformed = df.copy()\n",
    "    for col in df_transformed.select_dtypes(include=np.number).columns:\n",
    "        qt = QuantileTransformer(output_distribution='normal', n_quantiles=min(1000, len(df)))\n",
    "        df_transformed[col] = qt.fit_transform(df_transformed[[col]]).ravel()\n",
    "    return df_transformed\n",
    "\n",
    "def get_data(target, clipiqr=False, quantiletransform=False, threshold=0.1, get_test=False):\n",
    "    X_test = pd.read_csv(\"/pscratch/sd/r/ritesh11/temp_dir/dataset/test.csv\")\n",
    "    X_train = pd.read_csv(f\"{BASE_PATH}/train/{target}_X.csv\")\n",
    "    y_train = pd.read_csv(f\"{BASE_PATH}/train/{target}_y.csv\")\n",
    "    X_val = pd.read_csv(f\"{BASE_PATH}/val/{target}_X.csv\")\n",
    "    y_val = pd.read_csv(f\"{BASE_PATH}/val/{target}_y.csv\")\n",
    "    \n",
    "    # Optional preprocessing\n",
    "    if clipiqr:\n",
    "        X_train, clip_info_train = clip_outliers_iqr(X_train)\n",
    "        X_val, clip_info_val = clip_outliers_iqr(X_val)\n",
    "        if get_test:\n",
    "            X_test, clip_info_val = clip_outliers_iqr(X_test)\n",
    "\n",
    "    if quantiletransform:\n",
    "        X_train = apply_quantile_transform(X_train)\n",
    "        X_val = apply_quantile_transform(X_val)\n",
    "        if get_test:\n",
    "            X_test = apply_quantile_transform(X_test)\n",
    "        \n",
    "    # Feature engineering\n",
    "    X_train = pd.concat([X_train, compute_volume_weighted_component_features(X_train)], axis=1)\n",
    "    X_val = pd.concat([X_val, compute_volume_weighted_component_features(X_val)], axis=1)\n",
    "    if get_test:\n",
    "        X_test = pd.concat([X_test, compute_volume_weighted_component_features(X_test)], axis=1)\n",
    "\n",
    "    # Feature selection\n",
    "    df = pd.read_csv(os.path.join(\"/pscratch/sd/r/ritesh11/temp_dir/feature_importance\", f\"{target}.csv\"))\n",
    "    cols = df[df[\"importance\"] > threshold].iloc[:, 0].tolist()\n",
    "    # print(f\"Selected features ({len(cols)}):\", cols)\n",
    "    X_train = X_train[cols]\n",
    "    X_val = X_val[cols]\n",
    "    if get_test:\n",
    "        X_test = X_test[cols]\n",
    "    if get_test:\n",
    "        return X_train.values, y_train.values.ravel(), X_val.values, y_val.values.ravel(), X_test.values\n",
    "        \n",
    "    return X_train.values, y_train.values.ravel(), X_val.values, y_val.values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b74308f-f0ab-4fc0-8b78-732f8fa5a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = [f\"BlendProperty{i}\" for i in range(1, 11)]\n",
    "BASE_PATH = \"/pscratch/sd/r/ritesh11/temp_dir/dataset/updated\"\n",
    "model_dir = \"/pscratch/sd/r/ritesh11/temp_dir/LGBM_models\"\n",
    "N_TRIALS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da891628-f7a9-46c5-acdf-e61354e10cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_fixed_params = {\n",
    "    \"random_state\": 42,\n",
    "    \"optimizer\" : \"fmin_l_bfgs_b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2b297c3-bb1e-41d3-b75d-e486424f0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_fixed_params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"n_estimators\" : 2000,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"device_type\": \"cpu\",\n",
    "    # \"gpu_use_dp\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc61bf3e-ff55-4fcc-ab18-f1e6581767a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(trial):\n",
    "    kernel_choice = trial.suggest_categorical(\"kernel\", [\n",
    "        \"RBF\", \"Matern\", \"RQ\", \"DotProduct\"\n",
    "    ])\n",
    "\n",
    "    if kernel_choice == \"RBF\":\n",
    "        base_kernel = RBF(length_scale_bounds=(1e-5,1e5))\n",
    "\n",
    "    elif kernel_choice == \"Matern\":\n",
    "        nu = trial.suggest_categorical(\"matern_nu\", [0.5, 1.5, 2.5])\n",
    "        base_kernel = Matern(nu=nu,length_scale_bounds=(1e-5,1e5))\n",
    "\n",
    "    elif kernel_choice == \"RQ\":\n",
    "        base_kernel = RationalQuadratic(length_scale_bounds=(1e-5,1e5),alpha_bounds=(1e-5,1e5))\n",
    "\n",
    "    elif kernel_choice == \"DotProduct\":\n",
    "        base_kernel = DotProduct(sigma_0_bounds=(1e-5,1e5))\n",
    "\n",
    "    return base_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3da0bc8-d3dd-4d09-ace9-9aa7135e0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from optuna.exceptions import TrialPruned\n",
    "from numpy.linalg import LinAlgError\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "def train_gpr(trial, X_train, y_train):\n",
    "    \n",
    "    kernel = get_kernel(trial) \n",
    "    \n",
    "    params = {\n",
    "        \"kernel\": kernel,  # define this or tune externally\n",
    "        \"alpha\": trial.suggest_float(\"gpr_alpha\", 1e-12, 1e-3, log=True),\n",
    "        \"n_restarts_optimizer\": trial.suggest_categorical(\"gpr_n_restarts_optimizer\", [0, 1]),  \n",
    "        \"normalize_y\": trial.suggest_categorical(\"gpr_normalize_y\", [True, False]), \n",
    "    }\n",
    "    try:\n",
    "        model = GaussianProcessRegressor(**params, **gpr_fixed_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    except (LinAlgError, ValueError) as e:\n",
    "        raise TrialPruned(f\"GPR fitting failed: {e}\")\n",
    "\n",
    "def train_lgb(trial, X_train, y_train, X_val, y_val):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"lgb_lr\", 1e-3, 0.3, log=True),\n",
    "        # \"boosting_type\" : trial.suggest_categorical(\"lgb_boosting_type\", [\"gbdt\", \"dart\"]),\n",
    "        \"max_depth\": trial.suggest_int(\"lgb_max_depth\", 3, 12),\n",
    "        \"num_leaves\": trial.suggest_int(\"lgb_num_leaves\", 16, 256),\n",
    "        \"reg_lambda\": trial.suggest_float(\"lgb_reg_lambda\", 1e-4, 100.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"lgb_reg_alpha\", 1e-4, 100.0, log=True),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"lgb_bagging_fraction\", 0.5, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"lgb_bagging_freq\", 1, 7),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"lgb_colsample_bytree\", 0.4, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"lgb_min_child_weight\", 1e-2, 10.0, log=True),\n",
    "        \"min_child_samples\": trial.suggest_int(\"lgb_min_child_samples\", 5, 100),\n",
    "        \"min_split_gain\": trial.suggest_float(\"lgb_min_split_gain\", 0.0, 1.0),\n",
    "        \"max_bin\": trial.suggest_categorical(\"lgb_max_bin\", [128, 256, 512, 1024]),\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**params, **lgbm_fixed_params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"mape\",\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "            # LightGBMPruningCallback(trial, \"mape\")\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def objective(trial, target, n_splits=5, random_state=42):\n",
    "    # Preprocess choices\n",
    "    clipping = trial.suggest_categorical(\"clipping\", ['ciqr', 'qtr', False])\n",
    "    threshold = trial.suggest_categorical(\"threshold\", [0.0001, 0.001, 0.1, 0])\n",
    "    \n",
    "    clipiqr = clipping == 'ciqr'\n",
    "    quantiletransform = clipping == 'qtr'\n",
    "\n",
    "    # Combine train + val into full dataset\n",
    "    X_train, y_train, X_val, y_val = get_data(\n",
    "        target, clipiqr=clipiqr, quantiletransform=quantiletransform, threshold=threshold\n",
    "    )\n",
    "    X_all = np.concatenate([X_train, X_val], axis=0)\n",
    "    y_all = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "    # Stacking configuration\n",
    "    base_model_type = trial.suggest_categorical(\"base_model\", [\"gpr\", \"lgb\"])\n",
    "    meta_model_type = \"gpr\" if base_model_type == \"lgb\" else \"lgb\"\n",
    "    \n",
    "    if base_model_type == \"gpr\":\n",
    "        passthrough = True  # enforced\n",
    "    else:\n",
    "        passthrough = trial.suggest_categorical(\"passthrough\", [True, False])\n",
    "    \n",
    "    # Store per-fold metrics\n",
    "    fold_mapes = []\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_all)):\n",
    "        X_train_cv, y_train_cv = X_all[train_idx], y_all[train_idx]\n",
    "        X_val_cv, y_val_cv = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "        # === Train base model\n",
    "        if base_model_type == \"gpr\":\n",
    "            base_model = train_gpr(trial, X_train_cv, y_train_cv)\n",
    "        else:\n",
    "            base_model = train_lgb(trial, X_train_cv, y_train_cv, X_val_cv, y_val_cv)\n",
    "\n",
    "        base_preds_train = base_model.predict(X_train_cv)\n",
    "        base_preds_val = base_model.predict(X_val_cv)\n",
    "\n",
    "        # === Prepare meta model input\n",
    "        if passthrough:\n",
    "            X_meta_train = np.column_stack([X_train_cv, base_preds_train])\n",
    "            X_meta_val = np.column_stack([X_val_cv, base_preds_val])\n",
    "        else:\n",
    "            X_meta_train = base_preds_train.reshape(-1, 1)\n",
    "            X_meta_val = base_preds_val.reshape(-1, 1)\n",
    "\n",
    "        # === Train meta model\n",
    "        if meta_model_type == \"gpr\":\n",
    "            meta_model = train_gpr(trial, X_meta_train, y_train_cv)\n",
    "            meta_preds = meta_model.predict(X_meta_val)\n",
    "        else:\n",
    "            meta_model = train_lgb(trial, X_meta_train, y_train_cv, X_meta_val, y_val_cv)\n",
    "            meta_preds = meta_model.predict(X_meta_val)\n",
    "\n",
    "        # === Weighted ensemble\n",
    "        w_base = trial.suggest_float(\"w_base\", 0.0, 1.0)\n",
    "        w_meta = trial.suggest_float(\"w_meta\", 0.0, 1.0)\n",
    "        total_weight = w_base + w_meta + 1e-8\n",
    "        w_base /= total_weight\n",
    "        w_meta /= total_weight\n",
    "\n",
    "        final_preds = w_base * base_preds_val + w_meta * meta_preds\n",
    "\n",
    "        # === Metric\n",
    "        fold_mape = mean_absolute_percentage_error(y_val_cv, final_preds)\n",
    "        fold_mapes.append(fold_mape)\n",
    "\n",
    "    return np.mean(fold_mapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ce243a9-a1e4-4714-9e97-fb3ab97d92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial, target):\n",
    "#     # Preprocessing hyperparams\n",
    "#     clipping = trial.suggest_categorical(\"clipping\", ['ciqr', 'qtr', False])\n",
    "#     threshold = trial.suggest_categorical(\"threshold\", [float('-inf'), 0.0001, 0.001, 0.1, 0])\n",
    "    \n",
    "#     clipiqr = False\n",
    "#     quantiletransform = False\n",
    "\n",
    "#     if clipping=='ciqr':\n",
    "#         clipiqr = True\n",
    "#     elif clipping=='qtr':\n",
    "#         quantiletransform = True\n",
    "        \n",
    "#     # Load data with preprocessing\n",
    "#     X_train, y_train, X_val, y_val = get_data(\n",
    "#         target,\n",
    "#         clipiqr=clipiqr,\n",
    "#         quantiletransform=quantiletransform,\n",
    "#         threshold=threshold,\n",
    "#     )\n",
    "\n",
    "#     params = {\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "\n",
    "#         # Tree structure\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 256),\n",
    "\n",
    "#         # Regularization\n",
    "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-4, 100.0, log=True),\n",
    "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-4, 100.0, log=True),\n",
    "\n",
    "#         # Bagging\n",
    "#         \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "#         \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "\n",
    "#         # Feature sampling\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "\n",
    "#         # Leaf constraints\n",
    "#         \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-2, 10.0, log=True),\n",
    "#         \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "#         \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 0.0, 1.0),\n",
    "\n",
    "#         # Binning\n",
    "#         \"max_bin\": trial.suggest_categorical(\"max_bin\", [128, 256, 512, 1024])\n",
    "#     }\n",
    "\n",
    "#     model = lgb.LGBMRegressor(**params, **fixed_params)\n",
    "\n",
    "#     model.fit(\n",
    "#         X_train, y_train,\n",
    "#         eval_set=[(X_val, y_val)],\n",
    "#         eval_metric=\"mape\",\n",
    "#         callbacks=[\n",
    "#             lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "#             LightGBMPruningCallback(trial, \"mape\"),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     preds = model.predict(X_val)\n",
    "#     return mean_absolute_percentage_error(y_val, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed36c008-0776-4b56-8023-67b83da689d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_callback(study, trial):\n",
    "#         if trial.number % 50 == 0 and trial.value is not None:\n",
    "#             print(f\"Trial {trial.number}: MAPE = {trial.value:.4f}: BEST: {study.best_trial.value:.4f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58590c51-575a-4bbb-8ab8-151f55aa2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "675d34bc-8f37-4a63-a5b9-b53afe5fb44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target in TARGETS[7:]:\n",
    "#     # pruner = optuna.pruners.MedianPruner(n_startup_trials=50, n_warmup_steps=10)\n",
    "#     study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "#     study.optimize(\n",
    "#         lambda trial: objective(trial, target),\n",
    "#         n_trials=N_TRIALS,\n",
    "#         show_progress_bar=True,\n",
    "#         n_jobs=12\n",
    "#     )\n",
    "\n",
    "#     print(f\"\\nBest MAPE for {target}: {study.best_value:.4f}\")\n",
    "#     print(f\"Best params for {target}:\\n{study.best_params}\\n\")\n",
    "\n",
    "#     complete_params = {**study.best_params, **gpr_fixed_params, **lgbm_fixed_params}\n",
    "\n",
    "#     os.makedirs(model_dir, exist_ok=True)\n",
    "#     with open(os.path.join(model_dir, f\"best_params_{target}_gprexperiment.json\"), \"w\") as f:\n",
    "#         json.dump(complete_params, f, indent=2)\n",
    "        \n",
    "#     with open(os.path.join(model_dir, f\"best_mape_{target}.txt\"), \"w\") as f:\n",
    "#         f.write(f\"{study.best_value:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a521486d-5ac3-446c-9012-01e68c639135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_data(target,config):\n",
    "    return get_data(\n",
    "        target,\n",
    "        clipiqr=config['clipping'] == 'ciqr',\n",
    "        quantiletransform=config['clipping'] == 'qtr',\n",
    "        threshold=config['threshold'],\n",
    "        get_test=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15b1748b-ecd1-414e-8df5-20fa3c3c3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train base LightGBM model\n",
    "def train_lgb_model(X_train, y_train, X_val, y_val):\n",
    "    model = lgb.LGBMRegressor(\n",
    "        learning_rate=config['lgb_lr'],\n",
    "        max_depth=config['lgb_max_depth'],\n",
    "        num_leaves=config['lgb_num_leaves'],\n",
    "        reg_lambda=config['lgb_reg_lambda'],\n",
    "        reg_alpha=config['lgb_reg_alpha'],\n",
    "        bagging_fraction=config['lgb_bagging_fraction'],\n",
    "        bagging_freq=config['lgb_bagging_freq'],\n",
    "        colsample_bytree=config['lgb_colsample_bytree'],\n",
    "        min_child_weight=config['lgb_min_child_weight'],\n",
    "        min_child_samples=config['lgb_min_child_samples'],\n",
    "        min_split_gain=config['lgb_min_split_gain'],\n",
    "        max_bin=config['lgb_max_bin'],\n",
    "        **lgbm_fixed_params\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='mape',\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Train GPR model\n",
    "def train_gpr_model(X_train, y_train):\n",
    "    kernel = get_kernel_from_config(config)\n",
    "    model = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=config['gpr_alpha'],\n",
    "        n_restarts_optimizer=config['gpr_n_restarts_optimizer'],\n",
    "        normalize_y=config['gpr_normalize_y'],\n",
    "        **gpr_fixed_params\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa359b8c-1715-4ac9-8a80-d903dc732f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_from_config(config):\n",
    "    kernel_choice = config.get(\"kernel\", \"RBF\")\n",
    "\n",
    "    if kernel_choice == \"RBF\":\n",
    "        return RBF(length_scale_bounds=(1e-5, 1e5))\n",
    "\n",
    "    elif kernel_choice == \"Matern\":\n",
    "        nu = config.get(\"matern_nu\", 1.5)  # default to 1.5 if not specified\n",
    "        return Matern(nu=nu, length_scale_bounds=(1e-5, 1e5))\n",
    "\n",
    "    elif kernel_choice == \"RQ\":\n",
    "        return RationalQuadratic(length_scale_bounds=(1e-5, 1e5), alpha_bounds=(1e-5, 1e5))\n",
    "\n",
    "    elif kernel_choice == \"DotProduct\":\n",
    "        return DotProduct(sigma_0_bounds=(1e-5, 1e5))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported kernel choice: {kernel_choice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e66d4624-628d-4c17-b62a-f61f091ba138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stacked_model(target,config):\n",
    "    # Split data\n",
    "    X_train, y_train, X_val, y_val, X_test = get_fixed_data(target,config)\n",
    "    X_all = np.concatenate([X_train, X_val], axis=0)\n",
    "    y_all = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "    base_model_type = config['base_model'] \n",
    "    meta_model_type = \"gpr\" if base_model_type == \"lgb\" else \"lgb\"\n",
    "    passthrough = config.get('passthrough',True)\n",
    "\n",
    "    # === Base Model\n",
    "    if base_model_type == 'lgb':\n",
    "        base_model = train_lgb_model(X_train, y_train, X_val, y_val)\n",
    "        try:\n",
    "            print(f\"[Base LGBM] used {base_model.best_iteration_} estimators\")\n",
    "        except AttributeError:\n",
    "            print(\"[Base LGBM] did not use early stopping or no best_iteration_ found\")\n",
    "    else:\n",
    "        base_model = train_gpr_model(X_all, y_all)\n",
    "\n",
    "    base_preds_train = base_model.predict(X_train)\n",
    "    base_preds_val = base_model.predict(X_val)\n",
    "    base_preds_test = base_model.predict(X_test)\n",
    "    \n",
    "    # === Meta Input\n",
    "    if passthrough:\n",
    "        X_meta_train = np.column_stack([X_train, base_preds_train])\n",
    "        X_meta_val = np.column_stack([X_val, base_preds_val])\n",
    "        X_meta_test = np.column_stack([X_test, base_preds_test])\n",
    "        X_meta_all = np.vstack([X_meta_train, X_meta_val])\n",
    "    else:\n",
    "        X_meta_train = base_preds_train.reshape(-1, 1)\n",
    "        X_meta_val = base_preds_val.reshape(-1, 1)\n",
    "        X_meta_test = base_preds_test.reshape(-1, 1)\n",
    "        X_meta_all = np.vstack([X_meta_train, X_meta_val])\n",
    "\n",
    "    if meta_model_type == \"gpr\":\n",
    "        meta_model = train_gpr_model(X_meta_all, y_all)\n",
    "        meta_preds = meta_model.predict(X_meta_test)\n",
    "    else:\n",
    "        meta_model = train_lgb_model(X_meta_train, y_train, X_meta_val, y_val)\n",
    "        meta_preds = meta_model.predict(X_meta_test)\n",
    "\n",
    "    # === Weighted Ensemble\n",
    "    w_base = config['w_base']\n",
    "    w_meta = config['w_meta']\n",
    "    total = w_base + w_meta + 1e-8\n",
    "    w_base /= total\n",
    "    w_meta /= total\n",
    "\n",
    "    final_preds = w_base * base_preds_test + w_meta * meta_preds\n",
    "\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6df05ef6-fcab-4ab8-b3d3-8aeb3da2620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3f84693-098e-4677-af81-800b80c941a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Base LGBM] used 1417 estimators\n",
      "[Base LGBM] used 1223 estimators\n",
      "[Base LGBM] used 572 estimators\n"
     ]
    }
   ],
   "source": [
    "for target in TARGETS:\n",
    "    with open(os.path.join(model_dir, f\"best_params_{target}_gprexperiment.json\"), \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    res[target] = train_stacked_model(target,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd5a46fd-7871-454f-9cd6-32bd3dd6dd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlendProperty1</th>\n",
       "      <th>BlendProperty2</th>\n",
       "      <th>BlendProperty3</th>\n",
       "      <th>BlendProperty4</th>\n",
       "      <th>BlendProperty5</th>\n",
       "      <th>BlendProperty6</th>\n",
       "      <th>BlendProperty7</th>\n",
       "      <th>BlendProperty8</th>\n",
       "      <th>BlendProperty9</th>\n",
       "      <th>BlendProperty10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.154898</td>\n",
       "      <td>0.251252</td>\n",
       "      <td>0.721554</td>\n",
       "      <td>0.562056</td>\n",
       "      <td>0.340857</td>\n",
       "      <td>0.713312</td>\n",
       "      <td>0.686304</td>\n",
       "      <td>0.371897</td>\n",
       "      <td>-0.311870</td>\n",
       "      <td>0.326182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.810104</td>\n",
       "      <td>-0.588758</td>\n",
       "      <td>-1.149076</td>\n",
       "      <td>0.056294</td>\n",
       "      <td>-0.730921</td>\n",
       "      <td>-0.103821</td>\n",
       "      <td>-0.968339</td>\n",
       "      <td>-0.961511</td>\n",
       "      <td>-1.061895</td>\n",
       "      <td>0.007668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.769542</td>\n",
       "      <td>1.139059</td>\n",
       "      <td>1.120918</td>\n",
       "      <td>1.047087</td>\n",
       "      <td>2.485193</td>\n",
       "      <td>1.861209</td>\n",
       "      <td>1.006254</td>\n",
       "      <td>2.002036</td>\n",
       "      <td>0.349134</td>\n",
       "      <td>2.223461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.453284</td>\n",
       "      <td>0.295343</td>\n",
       "      <td>0.924950</td>\n",
       "      <td>-0.684258</td>\n",
       "      <td>1.912963</td>\n",
       "      <td>-0.438880</td>\n",
       "      <td>0.917463</td>\n",
       "      <td>1.606631</td>\n",
       "      <td>0.802194</td>\n",
       "      <td>-0.936379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.155276</td>\n",
       "      <td>-1.138684</td>\n",
       "      <td>1.149454</td>\n",
       "      <td>0.451078</td>\n",
       "      <td>2.135648</td>\n",
       "      <td>0.237306</td>\n",
       "      <td>0.982660</td>\n",
       "      <td>0.205062</td>\n",
       "      <td>-0.055396</td>\n",
       "      <td>1.075128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.169084</td>\n",
       "      <td>-0.880250</td>\n",
       "      <td>1.106266</td>\n",
       "      <td>-0.274813</td>\n",
       "      <td>-0.269777</td>\n",
       "      <td>-0.742171</td>\n",
       "      <td>1.072742</td>\n",
       "      <td>-0.497242</td>\n",
       "      <td>-1.359244</td>\n",
       "      <td>-0.446446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-2.175267</td>\n",
       "      <td>-1.310912</td>\n",
       "      <td>-1.126352</td>\n",
       "      <td>-2.300229</td>\n",
       "      <td>-0.626259</td>\n",
       "      <td>-2.460529</td>\n",
       "      <td>-1.094580</td>\n",
       "      <td>-1.847499</td>\n",
       "      <td>-1.442878</td>\n",
       "      <td>-1.296665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1.977994</td>\n",
       "      <td>2.199151</td>\n",
       "      <td>0.301280</td>\n",
       "      <td>1.133344</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.660378</td>\n",
       "      <td>0.276348</td>\n",
       "      <td>0.923305</td>\n",
       "      <td>0.264307</td>\n",
       "      <td>0.450129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-0.137799</td>\n",
       "      <td>0.822333</td>\n",
       "      <td>1.602543</td>\n",
       "      <td>-1.385970</td>\n",
       "      <td>-0.906719</td>\n",
       "      <td>0.177172</td>\n",
       "      <td>1.907439</td>\n",
       "      <td>0.561952</td>\n",
       "      <td>0.218511</td>\n",
       "      <td>1.277569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-1.035681</td>\n",
       "      <td>-1.917488</td>\n",
       "      <td>-1.934106</td>\n",
       "      <td>-1.646838</td>\n",
       "      <td>-0.023207</td>\n",
       "      <td>-1.818366</td>\n",
       "      <td>-1.955006</td>\n",
       "      <td>-1.893446</td>\n",
       "      <td>-2.304943</td>\n",
       "      <td>-0.194729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n",
       "0          0.154898        0.251252        0.721554        0.562056   \n",
       "1         -0.810104       -0.588758       -1.149076        0.056294   \n",
       "2          1.769542        1.139059        1.120918        1.047087   \n",
       "3         -0.453284        0.295343        0.924950       -0.684258   \n",
       "4          0.155276       -1.138684        1.149454        0.451078   \n",
       "..              ...             ...             ...             ...   \n",
       "495        0.169084       -0.880250        1.106266       -0.274813   \n",
       "496       -2.175267       -1.310912       -1.126352       -2.300229   \n",
       "497        1.977994        2.199151        0.301280        1.133344   \n",
       "498       -0.137799        0.822333        1.602543       -1.385970   \n",
       "499       -1.035681       -1.917488       -1.934106       -1.646838   \n",
       "\n",
       "     BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n",
       "0          0.340857        0.713312        0.686304        0.371897   \n",
       "1         -0.730921       -0.103821       -0.968339       -0.961511   \n",
       "2          2.485193        1.861209        1.006254        2.002036   \n",
       "3          1.912963       -0.438880        0.917463        1.606631   \n",
       "4          2.135648        0.237306        0.982660        0.205062   \n",
       "..              ...             ...             ...             ...   \n",
       "495       -0.269777       -0.742171        1.072742       -0.497242   \n",
       "496       -0.626259       -2.460529       -1.094580       -1.847499   \n",
       "497        0.001200        0.660378        0.276348        0.923305   \n",
       "498       -0.906719        0.177172        1.907439        0.561952   \n",
       "499       -0.023207       -1.818366       -1.955006       -1.893446   \n",
       "\n",
       "     BlendProperty9  BlendProperty10  \n",
       "0         -0.311870         0.326182  \n",
       "1         -1.061895         0.007668  \n",
       "2          0.349134         2.223461  \n",
       "3          0.802194        -0.936379  \n",
       "4         -0.055396         1.075128  \n",
       "..              ...              ...  \n",
       "495       -1.359244        -0.446446  \n",
       "496       -1.442878        -1.296665  \n",
       "497        0.264307         0.450129  \n",
       "498        0.218511         1.277569  \n",
       "499       -2.304943        -0.194729  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8bf8e85-f718-42f2-82b0-5c2ab824cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/pscratch/sd/r/ritesh11/temp_dir/dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cf77fde-0504-46df-95f2-e3b6c33460ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)\n",
    "df.insert(0, 'ID', test_df.index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16ee7419-3724-4c86-a302-e94651423d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"LGBM+GPR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193eeb74-e18f-4529-833e-c8cb76850425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv_3.12)\n",
   "language": "python",
   "name": "myenv_3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
