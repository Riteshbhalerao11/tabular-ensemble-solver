{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fceb571-d9f5-425d-8fa3-04704cad0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadf5395-13fc-4c01-8a37-b09f88ecca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_volume_weighted_component_features(X):\n",
    "    \"\"\"\n",
    "    Computes individual volume-weighted features WjPk = Componentj_fraction * Componentj_Propertyk\n",
    "    for j in 1..5 and k in 1..10 (total 50 features).\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for comp_idx in range(1, 6):  # Components 1–5\n",
    "        for prop_idx in range(1, 11):  # Properties 1–10\n",
    "            vol_col = f'Component{comp_idx}_fraction'\n",
    "            prop_col = f'Component{comp_idx}_Property{prop_idx}'\n",
    "            feat_name = f'W{comp_idx}P{prop_idx}'\n",
    "            features[feat_name] = X[vol_col] * X[prop_col]\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c88498-9201-4af8-b9e1-4813a3c30210",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [f\"BlendProperty{i}\" for i in range(1, 11)]\n",
    "BASE_PATH = \"/pscratch/sd/r/ritesh11/temp_dir/dataset\"\n",
    "model_dir = \"/pscratch/sd/r/ritesh11/temp_dir/_models\"\n",
    "fi_path = \"/pscratch/sd/r/ritesh11/temp_dir/feature_importance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce243a9-a1e4-4714-9e97-fb3ab97d92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.common import space\n",
    "\n",
    "nn_options = {\n",
    "    'num_epochs': 1000,\n",
    "    \"epochs_wo_improve\": 200,\n",
    "    'learning_rate': space.Real(1e-4, 1e-2, log=True, default=5e-4),\n",
    "    \"num_layers\": space.Categorical(2, 3, 4, 6),\n",
    "    \"hidden_size\": space.Categorical(128, 256, 512, 64),\n",
    "    'activation': space.Categorical('relu','elu','tanh'),\n",
    "    'dropout_prob': space.Real(0.0, 0.5, default=0.1),\n",
    "    \"weight_decay\": space.Real(1e-12, 0.1, default=1e-6, log=True),\n",
    "    'batch_size': space.Categorical(8,16,32,64,128),\n",
    "    'optimizer': space.Categorical('adam', 'sgd'),\n",
    "    \"proc.skew_threshold\": space.Categorical(0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0),\n",
    "    \"use_batchnorm\": space.Categorical(False, True),\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58590c51-575a-4bbb-8ab8-151f55aa2b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty3_stacked\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.2b20250713\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       172.68 GB / 502.97 GB (34.3%)\n",
      "Disk Space Avail:   15446274.52 GB / 45921523.47 GB (33.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty3_stacked\"\n",
      "Train Data Rows:    1900\n",
      "Train Data Columns: 13\n",
      "Label Column:       BlendProperty3\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    176823.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.19 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['Component2_fraction', 'Component4_fraction', 'Component5_fraction', 'W1P7', 'Component3_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['Component2_fraction', 'Component4_fraction', 'Component5_fraction', 'W1P7', 'Component3_fraction', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.19 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Included models: ['TABPFN'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "\tThe models types ['TABPFN'] are not present in the model list specified by the user and will be ignored:\n",
      "Fitting 0 L1 models, fit_strategy=\"sequential\" ...\n",
      "No base models to train on, skipping auxiliary stack level 2...\n",
      "No base models to train on, skipping stack level 2...\n",
      "No base models to train on, skipping auxiliary stack level 3...\n",
      "Warning: AutoGluon did not successfully train any models\n",
      "AutoGluon training complete, total runtime = 0.04s ... Best model: None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     27\u001b[39m X_val = pd.DataFrame(\n\u001b[32m     28\u001b[39m     scaler.transform(X_val),\n\u001b[32m     29\u001b[39m     columns=X_val.columns,\n\u001b[32m     30\u001b[39m     index=X_val.index\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m predictor = TabularPredictor(\n\u001b[32m     34\u001b[39m     label=t,\n\u001b[32m     35\u001b[39m     problem_type=\u001b[33m\"\u001b[39m\u001b[33mregression\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     eval_metric=\u001b[33m\"\u001b[39m\u001b[33mmean_absolute_percentage_error\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# You can use \"rmse\", \"r2\", etc.\u001b[39;00m\n\u001b[32m     37\u001b[39m     path=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/pscratch/sd/r/ritesh11/temp_dir/NN_models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_stacked\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# tuning_data=pd.concat([X_val,y_val],axis=1),\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# hyperparameters={\"NN_TORCH\": nn_options},\u001b[39;49;00m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mincluded_model_types\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTABPFN\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_stack\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdynamic_stacking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# num_stack_levels = 3,\u001b[39;49;00m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# hyperparameter_tune_kwargs={\u001b[39;49;00m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#         'num_trials': 100, \u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#         'scheduler': 'local',\u001b[39;49;00m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#         'searcher': 'auto',\u001b[39;49;00m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     },\u001b[39;49;00m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_weighted_ensemble\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# use_bag_holdout = True,\u001b[39;49;00m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# fit_strategy='parallel'\u001b[39;49;00m\n\u001b[32m     56\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/autogluon/core/utils/decorators.py:31\u001b[39m, in \u001b[36munpack.<locals>._unpack_inner.<locals>._call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(*args, **kwargs):\n\u001b[32m     30\u001b[39m     gargs, gkwargs = g(*other_args, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1303\u001b[39m, in \u001b[36mTabularPredictor.fit\u001b[39m\u001b[34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1300\u001b[39m \u001b[38;5;66;03m# keep track of the fit strategy used for future calls\u001b[39;00m\n\u001b[32m   1301\u001b[39m \u001b[38;5;28mself\u001b[39m._fit_strategy = fit_strategy\n\u001b[32m-> \u001b[39m\u001b[32m1303\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1311\u001b[39m, in \u001b[36mTabularPredictor._fit\u001b[39m\u001b[34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[39m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28mself\u001b[39m._learner.fit(**ag_fit_kwargs)\n\u001b[32m   1310\u001b[39m \u001b[38;5;28mself\u001b[39m._set_post_fit_vars()\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28mself\u001b[39m.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1643\u001b[39m, in \u001b[36mTabularPredictor._post_fit\u001b[39m\u001b[34m(self, keep_only_best, refit_full, set_best_to_refit_full, save_space, calibrate, calibrate_decision_threshold, infer_limit, num_cpus, num_gpus, refit_full_kwargs, fit_strategy, raise_on_no_models_fitted)\u001b[39m\n\u001b[32m   1641\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_names():\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_no_models_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1643\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1644\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNo models were trained successfully during fit().\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1645\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Inspect the log output or increase verbosity to determine why no models were fit.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1646\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Alternatively, set `raise_on_no_models_fitted` to False during the fit call.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1647\u001b[39m         )\n\u001b[32m   1649\u001b[39m     logger.log(\u001b[32m30\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWarning: No models found, skipping post_fit logic...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1650\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call."
     ]
    }
   ],
   "source": [
    "for t in targets[2:3]:\n",
    "    X_train = pd.read_csv(f\"{BASE_PATH}/train/{t}_X.csv\")\n",
    "    y_train = pd.read_csv(f\"{BASE_PATH}/train/{t}_y.csv\")\n",
    "    X_val = pd.read_csv(f\"{BASE_PATH}/val/{t}_X.csv\")\n",
    "    y_val = pd.read_csv(f\"{BASE_PATH}/val/{t}_y.csv\")\n",
    "\n",
    "    df = pd.read_csv(os.path.join(fi_path, f\"{t}.csv\"))\n",
    "    cols = df[df[\"importance\"] > 0.1].iloc[:, 0].tolist()\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    blend_features = compute_volume_weighted_component_features(X_train)\n",
    "    X_train = pd.concat([X_train, blend_features], axis=1)\n",
    "    blend_features = compute_volume_weighted_component_features(X_val)\n",
    "    X_val = pd.concat([X_val, blend_features], axis=1)\n",
    "    \n",
    "    X_train = X_train[cols]\n",
    "    X_val = X_val[cols]\n",
    "    \n",
    "    X_train = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    \n",
    "    X_val = pd.DataFrame(\n",
    "        scaler.transform(X_val),\n",
    "        columns=X_val.columns,\n",
    "        index=X_val.index\n",
    "    )\n",
    "\n",
    "    predictor = TabularPredictor(\n",
    "        label=t,\n",
    "        problem_type=\"regression\",\n",
    "        eval_metric=\"mean_absolute_percentage_error\",  # You can use \"rmse\", \"r2\", etc.\n",
    "        path=f\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/{t}_stacked\",\n",
    "    )\n",
    "\n",
    "    predictor.fit(\n",
    "        train_data=pd.concat([X_train,y_train],axis=1),\n",
    "        # tuning_data=pd.concat([X_val,y_val],axis=1),\n",
    "        # hyperparameters={\"NN_TORCH\": nn_options},\n",
    "        included_model_types = ['TABPFN'],\n",
    "        auto_stack=True,\n",
    "        dynamic_stacking=False,\n",
    "        # num_stack_levels = 3,\n",
    "        # hyperparameter_tune_kwargs={\n",
    "        #         'num_trials': 100, \n",
    "        #         'scheduler': 'local',\n",
    "        #         'searcher': 'auto',\n",
    "        #     },\n",
    "        fit_weighted_ensemble=True,\n",
    "        # use_bag_holdout = True,\n",
    "        # fit_strategy='parallel'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28cae09a-d601-4200-9663-4d9e947fad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc3e645-b709-4ff9-87d8-57455d9d9053",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autogluon.tabular.models.TabMModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogluon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtabular\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mTabMModel\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'autogluon.tabular.models.TabMModel'"
     ]
    }
   ],
   "source": [
    "import autogluon.tabular.models.TabMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34b9c2bc-a6b3-4046-a6bb-757e5cf8cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "BX_train = predictor.predict(X_train)\n",
    "BX_train = BX_train.values.reshape(-1,1)\n",
    "\n",
    "BX_val = predictor.predict(X_val)\n",
    "BX_val = BX_val.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2099eda-b50c-4fc6-a51c-7ba4feff55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BX_y_val = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "136e79f2-90fd-4736-a0da-ccf655a26136",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [f\"BlendProperty{i}\" for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec501ec-00f6-4306-a60b-f2483eca80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/pscratch/sd/r/ritesh11/temp_dir/dataset/train.csv\")\n",
    "X_test = pd.read_csv(\"/pscratch/sd/r/ritesh11/temp_dir/dataset/test.csv\")\n",
    "X_train = data.iloc[:,:55]\n",
    "y = data.iloc[:,55:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ba356c-60c0-4ec2-a7da-a335b99125f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b3271d-6a08-47c1-bf2c-d59e4c539805",
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_features = compute_volume_weighted_component_features(X_train)\n",
    "X_train = pd.concat([X_train, blend_features], axis=1)\n",
    "X_train = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "\n",
    "blend_features = compute_volume_weighted_component_features(X_test)\n",
    "X_test = pd.concat([X_test, blend_features], axis=1)\n",
    "X_test = pd.DataFrame(\n",
    "        scaler.transform(X_test.iloc[:,1:]),\n",
    "        columns=X_train.columns,\n",
    "        index=X_test.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9045d59d-f591-4b1d-8095-0cdf70f5c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf0a1af-b7b9-4562-9e27-755a4a419a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>W5P1</th>\n",
       "      <th>W5P2</th>\n",
       "      <th>W5P3</th>\n",
       "      <th>W5P4</th>\n",
       "      <th>W5P5</th>\n",
       "      <th>W5P6</th>\n",
       "      <th>W5P7</th>\n",
       "      <th>W5P8</th>\n",
       "      <th>W5P9</th>\n",
       "      <th>W5P10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004229</td>\n",
       "      <td>-0.812096</td>\n",
       "      <td>0.843232</td>\n",
       "      <td>0.197826</td>\n",
       "      <td>-0.430053</td>\n",
       "      <td>-0.178197</td>\n",
       "      <td>-0.719470</td>\n",
       "      <td>0.769188</td>\n",
       "      <td>-0.866653</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367271</td>\n",
       "      <td>-1.242069</td>\n",
       "      <td>-0.671839</td>\n",
       "      <td>0.138527</td>\n",
       "      <td>-0.312304</td>\n",
       "      <td>-0.060883</td>\n",
       "      <td>-0.931487</td>\n",
       "      <td>-0.390980</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>-0.424760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.107444</td>\n",
       "      <td>1.937458</td>\n",
       "      <td>-1.081681</td>\n",
       "      <td>0.197826</td>\n",
       "      <td>0.193393</td>\n",
       "      <td>2.503180</td>\n",
       "      <td>0.193472</td>\n",
       "      <td>-0.501139</td>\n",
       "      <td>-0.190820</td>\n",
       "      <td>-1.907956</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.803644</td>\n",
       "      <td>0.294397</td>\n",
       "      <td>0.171549</td>\n",
       "      <td>1.480426</td>\n",
       "      <td>0.157005</td>\n",
       "      <td>-0.080499</td>\n",
       "      <td>1.176110</td>\n",
       "      <td>0.544844</td>\n",
       "      <td>0.488176</td>\n",
       "      <td>-1.214671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.126808</td>\n",
       "      <td>-1.117602</td>\n",
       "      <td>-0.059071</td>\n",
       "      <td>1.119267</td>\n",
       "      <td>0.692150</td>\n",
       "      <td>1.548360</td>\n",
       "      <td>0.903237</td>\n",
       "      <td>0.028964</td>\n",
       "      <td>-0.361620</td>\n",
       "      <td>-0.273995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342203</td>\n",
       "      <td>-1.064627</td>\n",
       "      <td>1.739907</td>\n",
       "      <td>-2.341116</td>\n",
       "      <td>1.844205</td>\n",
       "      <td>0.739504</td>\n",
       "      <td>0.190984</td>\n",
       "      <td>-0.260478</td>\n",
       "      <td>0.094617</td>\n",
       "      <td>-0.196013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.957042</td>\n",
       "      <td>-1.117602</td>\n",
       "      <td>-0.059071</td>\n",
       "      <td>-1.290655</td>\n",
       "      <td>0.692150</td>\n",
       "      <td>-0.425024</td>\n",
       "      <td>1.027852</td>\n",
       "      <td>-1.186331</td>\n",
       "      <td>-0.843959</td>\n",
       "      <td>-0.804655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.466778</td>\n",
       "      <td>-2.234812</td>\n",
       "      <td>-0.499662</td>\n",
       "      <td>-0.363466</td>\n",
       "      <td>-2.383778</td>\n",
       "      <td>-0.545705</td>\n",
       "      <td>2.142631</td>\n",
       "      <td>-0.948798</td>\n",
       "      <td>2.114722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.107444</td>\n",
       "      <td>-1.117602</td>\n",
       "      <td>1.925996</td>\n",
       "      <td>1.119267</td>\n",
       "      <td>-1.427567</td>\n",
       "      <td>-0.187462</td>\n",
       "      <td>-0.740295</td>\n",
       "      <td>-0.476025</td>\n",
       "      <td>2.065007</td>\n",
       "      <td>0.768160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>-0.001666</td>\n",
       "      <td>0.009909</td>\n",
       "      <td>-0.013205</td>\n",
       "      <td>0.018452</td>\n",
       "      <td>-0.013888</td>\n",
       "      <td>0.013271</td>\n",
       "      <td>-0.005846</td>\n",
       "      <td>-0.019667</td>\n",
       "      <td>0.019179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.589304</td>\n",
       "      <td>-1.056501</td>\n",
       "      <td>-0.600452</td>\n",
       "      <td>0.481346</td>\n",
       "      <td>-0.679432</td>\n",
       "      <td>1.037410</td>\n",
       "      <td>1.424216</td>\n",
       "      <td>0.792701</td>\n",
       "      <td>-0.439057</td>\n",
       "      <td>0.410072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190544</td>\n",
       "      <td>-0.109562</td>\n",
       "      <td>-0.174514</td>\n",
       "      <td>0.551778</td>\n",
       "      <td>0.097216</td>\n",
       "      <td>-0.882690</td>\n",
       "      <td>-0.362998</td>\n",
       "      <td>-0.191655</td>\n",
       "      <td>-0.599596</td>\n",
       "      <td>0.378399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.057061</td>\n",
       "      <td>1.754155</td>\n",
       "      <td>-0.901220</td>\n",
       "      <td>-0.794494</td>\n",
       "      <td>-0.430053</td>\n",
       "      <td>-1.306463</td>\n",
       "      <td>-1.494420</td>\n",
       "      <td>-0.992620</td>\n",
       "      <td>0.901859</td>\n",
       "      <td>1.040874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615029</td>\n",
       "      <td>-0.114417</td>\n",
       "      <td>0.824026</td>\n",
       "      <td>0.114048</td>\n",
       "      <td>-0.355249</td>\n",
       "      <td>-0.712562</td>\n",
       "      <td>-0.709778</td>\n",
       "      <td>0.589479</td>\n",
       "      <td>0.191558</td>\n",
       "      <td>-0.928177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1.528014</td>\n",
       "      <td>-1.056501</td>\n",
       "      <td>-0.359838</td>\n",
       "      <td>-0.936255</td>\n",
       "      <td>1.440286</td>\n",
       "      <td>0.807013</td>\n",
       "      <td>0.620821</td>\n",
       "      <td>0.357852</td>\n",
       "      <td>0.286144</td>\n",
       "      <td>1.040874</td>\n",
       "      <td>...</td>\n",
       "      <td>1.731995</td>\n",
       "      <td>2.071313</td>\n",
       "      <td>-1.261354</td>\n",
       "      <td>2.560755</td>\n",
       "      <td>0.346698</td>\n",
       "      <td>-2.273392</td>\n",
       "      <td>-1.925717</td>\n",
       "      <td>0.384031</td>\n",
       "      <td>-2.687372</td>\n",
       "      <td>-0.016989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-0.923575</td>\n",
       "      <td>-0.873197</td>\n",
       "      <td>1.444767</td>\n",
       "      <td>0.552226</td>\n",
       "      <td>-0.305364</td>\n",
       "      <td>-0.793042</td>\n",
       "      <td>0.687361</td>\n",
       "      <td>-1.787675</td>\n",
       "      <td>0.847314</td>\n",
       "      <td>0.181414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126330</td>\n",
       "      <td>0.809500</td>\n",
       "      <td>-0.769716</td>\n",
       "      <td>-0.780904</td>\n",
       "      <td>-0.786315</td>\n",
       "      <td>0.050920</td>\n",
       "      <td>-0.765468</td>\n",
       "      <td>1.131583</td>\n",
       "      <td>-1.256999</td>\n",
       "      <td>-0.479139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-1.107444</td>\n",
       "      <td>1.937458</td>\n",
       "      <td>-1.081681</td>\n",
       "      <td>1.119267</td>\n",
       "      <td>-1.427567</td>\n",
       "      <td>-0.328295</td>\n",
       "      <td>0.263737</td>\n",
       "      <td>-1.202441</td>\n",
       "      <td>1.837673</td>\n",
       "      <td>0.783841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>-0.001666</td>\n",
       "      <td>0.009909</td>\n",
       "      <td>-0.013205</td>\n",
       "      <td>0.018452</td>\n",
       "      <td>-0.013888</td>\n",
       "      <td>0.013271</td>\n",
       "      <td>-0.005846</td>\n",
       "      <td>-0.019667</td>\n",
       "      <td>0.019179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Component1_fraction  Component2_fraction  Component3_fraction  \\\n",
       "0              -0.004229            -0.812096             0.843232   \n",
       "1              -1.107444             1.937458            -1.081681   \n",
       "2              -0.126808            -1.117602            -0.059071   \n",
       "3               1.957042            -1.117602            -0.059071   \n",
       "4              -1.107444            -1.117602             1.925996   \n",
       "..                   ...                  ...                  ...   \n",
       "495             1.589304            -1.056501            -0.600452   \n",
       "496             0.057061             1.754155            -0.901220   \n",
       "497             1.528014            -1.056501            -0.359838   \n",
       "498            -0.923575            -0.873197             1.444767   \n",
       "499            -1.107444             1.937458            -1.081681   \n",
       "\n",
       "     Component4_fraction  Component5_fraction  Component1_Property1  \\\n",
       "0               0.197826            -0.430053             -0.178197   \n",
       "1               0.197826             0.193393              2.503180   \n",
       "2               1.119267             0.692150              1.548360   \n",
       "3              -1.290655             0.692150             -0.425024   \n",
       "4               1.119267            -1.427567             -0.187462   \n",
       "..                   ...                  ...                   ...   \n",
       "495             0.481346            -0.679432              1.037410   \n",
       "496            -0.794494            -0.430053             -1.306463   \n",
       "497            -0.936255             1.440286              0.807013   \n",
       "498             0.552226            -0.305364             -0.793042   \n",
       "499             1.119267            -1.427567             -0.328295   \n",
       "\n",
       "     Component2_Property1  Component3_Property1  Component4_Property1  \\\n",
       "0               -0.719470              0.769188             -0.866653   \n",
       "1                0.193472             -0.501139             -0.190820   \n",
       "2                0.903237              0.028964             -0.361620   \n",
       "3                1.027852             -1.186331             -0.843959   \n",
       "4               -0.740295             -0.476025              2.065007   \n",
       "..                    ...                   ...                   ...   \n",
       "495              1.424216              0.792701             -0.439057   \n",
       "496             -1.494420             -0.992620              0.901859   \n",
       "497              0.620821              0.357852              0.286144   \n",
       "498              0.687361             -1.787675              0.847314   \n",
       "499              0.263737             -1.202441              1.837673   \n",
       "\n",
       "     Component5_Property1  ...      W5P1      W5P2      W5P3      W5P4  \\\n",
       "0                0.615500  ...  0.367271 -1.242069 -0.671839  0.138527   \n",
       "1               -1.907956  ... -1.803644  0.294397  0.171549  1.480426   \n",
       "2               -0.273995  ... -0.342203 -1.064627  1.739907 -2.341116   \n",
       "3               -0.804655  ... -0.999000 -0.466778 -2.234812 -0.499662   \n",
       "4                0.768160  ...  0.019313 -0.001666  0.009909 -0.013205   \n",
       "..                    ...  ...       ...       ...       ...       ...   \n",
       "495              0.410072  ...  0.190544 -0.109562 -0.174514  0.551778   \n",
       "496              1.040874  ...  0.615029 -0.114417  0.824026  0.114048   \n",
       "497              1.040874  ...  1.731995  2.071313 -1.261354  2.560755   \n",
       "498              0.181414  ...  0.126330  0.809500 -0.769716 -0.780904   \n",
       "499              0.783841  ...  0.019313 -0.001666  0.009909 -0.013205   \n",
       "\n",
       "         W5P5      W5P6      W5P7      W5P8      W5P9     W5P10  \n",
       "0   -0.312304 -0.060883 -0.931487 -0.390980  0.726688 -0.424760  \n",
       "1    0.157005 -0.080499  1.176110  0.544844  0.488176 -1.214671  \n",
       "2    1.844205  0.739504  0.190984 -0.260478  0.094617 -0.196013  \n",
       "3   -0.363466 -2.383778 -0.545705  2.142631 -0.948798  2.114722  \n",
       "4    0.018452 -0.013888  0.013271 -0.005846 -0.019667  0.019179  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "495  0.097216 -0.882690 -0.362998 -0.191655 -0.599596  0.378399  \n",
       "496 -0.355249 -0.712562 -0.709778  0.589479  0.191558 -0.928177  \n",
       "497  0.346698 -2.273392 -1.925717  0.384031 -2.687372 -0.016989  \n",
       "498 -0.786315  0.050920 -0.765468  1.131583 -1.256999 -0.479139  \n",
       "499  0.018452 -0.013888  0.013271 -0.005846 -0.019667  0.019179  \n",
       "\n",
       "[500 rows x 105 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa2cede-1199-493c-8c05-2d8a8d4e1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b7777e-1063-4690-ab1f-13d1c75b3854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty1_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/autogluon/common/utils/utils.py:97: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       133.88 GB / 502.97 GB (26.6%)\n",
      "Disk Space Avail:   15342264.55 GB / 45921523.47 GB (33.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty1_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty1\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    137085.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 1.3, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.08190442404668141, 'optimizer': 'adam', 'learning_rate': 0.00015321085601173971, 'weight_decay': 3.3761492236278096e-05, 'proc.embed_min_categories': 100, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 10000, 'proc.skew_threshold': 100.0, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto', 'batch_size': 16}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0417\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t104.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 104.29s ... Best model: NeuralNetTorch | Estimated inference throughput: 496.1 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty1_full\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty2_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       138.15 GB / 502.97 GB (27.5%)\n",
      "Disk Space Avail:   15340406.16 GB / 45921523.47 GB (33.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty2_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty2\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    141451.70 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 0.5, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.40863853592875415, 'optimizer': 'adam', 'learning_rate': 0.002158043614914502, 'weight_decay': 1.3762687436224787e-06, 'proc.embed_min_categories': 100, 'proc.impute_strategy': 'mean', 'proc.max_category_levels': 500, 'proc.skew_threshold': 1.0, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 512, 'max_batch_size': 512, 'use_batchnorm': True, 'loss_function': 'auto', 'batch_size': 128}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0051\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t118.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 118.56s ... Best model: NeuralNetTorch | Estimated inference throughput: 376.3 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty2_full\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty3_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       140.60 GB / 502.97 GB (28.0%)\n",
      "Disk Space Avail:   15338327.11 GB / 45921523.47 GB (33.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty3_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty3\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    143968.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 1.3, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.2544530454673136, 'optimizer': 'adam', 'learning_rate': 0.005889164083639445, 'weight_decay': 3.502858310069699e-05, 'proc.embed_min_categories': 100, 'proc.impute_strategy': 'mean', 'proc.max_category_levels': 1000, 'proc.skew_threshold': 1.0, 'use_ngram_features': False, 'num_layers': 6, 'hidden_size': 256, 'max_batch_size': 512, 'use_batchnorm': True, 'loss_function': 'auto', 'batch_size': 128}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0252\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t129.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 129.34s ... Best model: NeuralNetTorch | Estimated inference throughput: 362.8 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty3_full\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       139.67 GB / 502.97 GB (27.8%)\n",
      "Disk Space Avail:   15338699.41 GB / 45921523.47 GB (33.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty4_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty4_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty4\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    143033.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 0.9, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.011853248340682493, 'optimizer': 'adam', 'learning_rate': 0.0004702987141180395, 'weight_decay': 5.627651998129087e-07, 'proc.embed_min_categories': 10, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 400, 'proc.skew_threshold': 1.0, 'use_ngram_features': False, 'num_layers': 6, 'hidden_size': 64, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto', 'batch_size': 128}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0085\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t84.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 84.85s ... Best model: NeuralNetTorch | Estimated inference throughput: 318.4 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty4_full\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty5_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       139.56 GB / 502.97 GB (27.7%)\n",
      "Disk Space Avail:   15337189.20 GB / 45921523.47 GB (33.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty5_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty5\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    142882.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 0.6, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1983303164522095, 'optimizer': 'adam', 'learning_rate': 0.0003458366638710144, 'weight_decay': 0.0003077287634151853, 'proc.embed_min_categories': 100, 'proc.impute_strategy': 'mean', 'proc.max_category_levels': 400, 'proc.skew_threshold': 0.5, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 256, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto', 'batch_size': 64}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0146\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t86.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 86.18s ... Best model: NeuralNetTorch | Estimated inference throughput: 241.4 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty5_full\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       138.76 GB / 502.97 GB (27.6%)\n",
      "Disk Space Avail:   15335751.48 GB / 45921523.47 GB (33.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty6_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty6_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty6\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    142089.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 1.5, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.04226915828273245, 'optimizer': 'adam', 'learning_rate': 0.00017484508629084545, 'weight_decay': 2.0998660761568904e-10, 'proc.embed_min_categories': 1000, 'proc.impute_strategy': 'most_frequent', 'proc.max_category_levels': 1000, 'proc.skew_threshold': 0.999, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 256, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto', 'batch_size': 16}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0041\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t267.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 267.79s ... Best model: NeuralNetTorch | Estimated inference throughput: 375.6 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty6_full\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty7_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       141.08 GB / 502.97 GB (28.1%)\n",
      "Disk Space Avail:   15207649.74 GB / 45921523.47 GB (33.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty7_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty7\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    144471.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 0.9, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.39151458841583703, 'optimizer': 'adam', 'learning_rate': 0.008574087499022283, 'weight_decay': 2.7084219767069553e-05, 'proc.embed_min_categories': 10, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 10000, 'proc.skew_threshold': 10.0, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': True, 'loss_function': 'auto', 'batch_size': 64}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0167\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t215.66s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 216.0s ... Best model: NeuralNetTorch | Estimated inference throughput: 20.4 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty7_full\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty8_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       144.95 GB / 502.97 GB (28.8%)\n",
      "Disk Space Avail:   15076408.86 GB / 45921523.47 GB (32.8%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty8_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty8\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    148424.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 0.8, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.3647599887705672, 'optimizer': 'adam', 'learning_rate': 0.0036448187460393954, 'weight_decay': 1.4547425316824946e-05, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'mean', 'proc.max_category_levels': 300, 'proc.skew_threshold': 1.0, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': True, 'loss_function': 'auto', 'batch_size': 128}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0084\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t38.12s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 38.28s ... Best model: NeuralNetTorch | Estimated inference throughput: 170.1 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty8_full\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty9_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       142.52 GB / 502.97 GB (28.3%)\n",
      "Disk Space Avail:   15075580.62 GB / 45921523.47 GB (32.8%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty9_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty9\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    145977.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 1.4, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.48821531971273546, 'optimizer': 'adam', 'learning_rate': 0.0022431383613486246, 'weight_decay': 2.489339732992719e-06, 'proc.embed_min_categories': 3, 'proc.impute_strategy': 'mean', 'proc.max_category_levels': 10000, 'proc.skew_threshold': 0.8, 'use_ngram_features': False, 'num_layers': 2, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': True, 'loss_function': 'auto', 'batch_size': 32}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0927\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t105.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 105.95s ... Best model: NeuralNetTorch | Estimated inference throughput: 345.5 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty9_full\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETED /pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty10_full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Mar 13 20:09:44 UTC 2025 (330b47d)\n",
      "CPU Count:          256\n",
      "Memory Avail:       141.48 GB / 502.97 GB (28.1%)\n",
      "Disk Space Avail:   15074000.21 GB / 45921523.47 GB (32.8%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty10_full\"\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 105\n",
      "Label Column:       BlendProperty10\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Warning: Updated holdout_frac from 0 to 0.0015 to avoid cutting too many classes.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    144872.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 105 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t105 features in original data used to generate 105 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0015, Train Rows: 1997, Val Rows: 3\n",
      "Large model count detected (23 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 1000, 'epochs_wo_improve': 200, 'activation': 'elu', 'embedding_size_factor': 1.5, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.4604919079290231, 'optimizer': 'adam', 'learning_rate': 0.0004138138292612609, 'weight_decay': 4.483185465120868e-06, 'proc.embed_min_categories': 1000, 'proc.impute_strategy': 'most_frequent', 'proc.max_category_levels': 1000, 'proc.skew_threshold': 100.0, 'use_ngram_features': False, 'num_layers': 3, 'hidden_size': 512, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto', 'batch_size': 128}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0182\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t130.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.41s ... Best model: NeuralNetTorch | Estimated inference throughput: 549.1 rows/s (3 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/BlendProperty10_full\")\n"
     ]
    }
   ],
   "source": [
    "for t in targets:\n",
    "    model_dir = f\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/{t}\"\n",
    "    out_dir = f\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/{t}_full\"\n",
    "    if os.path.exists(out_dir):\n",
    "        shutil.rmtree(out_dir)\n",
    "        print(f\"DELETED {out_dir}\")\n",
    "    predictor = TabularPredictor.load(model_dir)\n",
    "    hps = predictor.model_hyperparameters(predictor.model_best,output_format='all')\n",
    "    predictor = TabularPredictor(\n",
    "        label=t,\n",
    "        problem_type=\"regression\",\n",
    "        eval_metric=\"mean_absolute_percentage_error\", \n",
    "        path=out_dir,\n",
    "    )\n",
    "    predictor.fit(\n",
    "        train_data=pd.concat([X_train,y[[t]]],axis=1),\n",
    "        hyperparameters={\"NN_TORCH\": hps},\n",
    "        auto_stack=False,\n",
    "        dynamic_stacking=False,\n",
    "        fit_weighted_ensemble=False,\n",
    "        holdout_frac = 0,\n",
    "        use_bag_holdout = False,\n",
    "    )\n",
    "    predictors.append(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4afdf77c-7517-40a7-b0d2-fee0305c2c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-0.041749</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>104.141014</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>104.141014</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  score_val                     eval_metric  pred_time_val  \\\n",
       "0  NeuralNetTorch  -0.041749  mean_absolute_percentage_error       0.006047   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  104.141014                0.006047         104.141014            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True          1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors[0].leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d1189a8-c558-4902-91a9-7918a66b0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7f2f286-991e-4574-afac-e5a9f278898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on test set: 100%|██████████| 10/10 [00:00<00:00, 55.62it/s]\n"
     ]
    }
   ],
   "source": [
    "test_preds = pd.DataFrame()\n",
    "idx = 0\n",
    "\n",
    "for target in tqdm(targets, desc=\"Predicting on test set\"):\n",
    "    \n",
    "    test_preds[target] = predictors[idx].predict(X_test)\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7dda809-2f61-46c9-98db-97bb55deb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.insert(0, 'ID', test_preds.index+1)\n",
    "test_preds.to_csv(\"MLP_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b960ee9c-4bc5-48d8-8de4-208b6b64e622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>BlendProperty1</th>\n",
       "      <th>BlendProperty2</th>\n",
       "      <th>BlendProperty3</th>\n",
       "      <th>BlendProperty4</th>\n",
       "      <th>BlendProperty5</th>\n",
       "      <th>BlendProperty6</th>\n",
       "      <th>BlendProperty7</th>\n",
       "      <th>BlendProperty8</th>\n",
       "      <th>BlendProperty9</th>\n",
       "      <th>BlendProperty10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.269499</td>\n",
       "      <td>0.181336</td>\n",
       "      <td>0.616583</td>\n",
       "      <td>0.590101</td>\n",
       "      <td>0.309642</td>\n",
       "      <td>0.759479</td>\n",
       "      <td>0.646484</td>\n",
       "      <td>0.301811</td>\n",
       "      <td>-0.218438</td>\n",
       "      <td>0.336122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.771319</td>\n",
       "      <td>-0.664547</td>\n",
       "      <td>-1.214896</td>\n",
       "      <td>0.059385</td>\n",
       "      <td>-0.753830</td>\n",
       "      <td>-0.054308</td>\n",
       "      <td>-1.145725</td>\n",
       "      <td>-1.064132</td>\n",
       "      <td>-0.901618</td>\n",
       "      <td>-0.021733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.601888</td>\n",
       "      <td>1.000914</td>\n",
       "      <td>1.043142</td>\n",
       "      <td>1.074902</td>\n",
       "      <td>2.328620</td>\n",
       "      <td>1.785143</td>\n",
       "      <td>1.047917</td>\n",
       "      <td>1.976724</td>\n",
       "      <td>0.675748</td>\n",
       "      <td>2.246820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.438803</td>\n",
       "      <td>0.269513</td>\n",
       "      <td>0.834678</td>\n",
       "      <td>-0.642701</td>\n",
       "      <td>1.502412</td>\n",
       "      <td>-0.433490</td>\n",
       "      <td>0.748223</td>\n",
       "      <td>1.870233</td>\n",
       "      <td>1.048527</td>\n",
       "      <td>-0.937008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.122862</td>\n",
       "      <td>-1.187016</td>\n",
       "      <td>1.043753</td>\n",
       "      <td>0.403289</td>\n",
       "      <td>2.416820</td>\n",
       "      <td>0.271279</td>\n",
       "      <td>1.059293</td>\n",
       "      <td>-0.103926</td>\n",
       "      <td>-0.579997</td>\n",
       "      <td>1.101275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>0.162771</td>\n",
       "      <td>-0.863502</td>\n",
       "      <td>1.060396</td>\n",
       "      <td>-0.285125</td>\n",
       "      <td>-0.179507</td>\n",
       "      <td>-0.746345</td>\n",
       "      <td>1.096318</td>\n",
       "      <td>-0.486561</td>\n",
       "      <td>-1.434873</td>\n",
       "      <td>-0.477653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>-1.853409</td>\n",
       "      <td>-1.344220</td>\n",
       "      <td>-1.043259</td>\n",
       "      <td>-2.193130</td>\n",
       "      <td>-0.642872</td>\n",
       "      <td>-2.138992</td>\n",
       "      <td>-0.976467</td>\n",
       "      <td>-1.863805</td>\n",
       "      <td>-1.520885</td>\n",
       "      <td>-1.317838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>1.765158</td>\n",
       "      <td>2.149623</td>\n",
       "      <td>0.365237</td>\n",
       "      <td>1.181389</td>\n",
       "      <td>-0.102844</td>\n",
       "      <td>0.651619</td>\n",
       "      <td>0.235907</td>\n",
       "      <td>0.976983</td>\n",
       "      <td>0.350661</td>\n",
       "      <td>0.458840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>0.752155</td>\n",
       "      <td>1.575431</td>\n",
       "      <td>-1.371880</td>\n",
       "      <td>-0.929406</td>\n",
       "      <td>0.115193</td>\n",
       "      <td>1.757926</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.383757</td>\n",
       "      <td>1.322213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>-1.017822</td>\n",
       "      <td>-1.982754</td>\n",
       "      <td>-1.982718</td>\n",
       "      <td>-1.667480</td>\n",
       "      <td>-0.086834</td>\n",
       "      <td>-1.822298</td>\n",
       "      <td>-1.879457</td>\n",
       "      <td>-1.887797</td>\n",
       "      <td>-2.307482</td>\n",
       "      <td>-0.229279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n",
       "0      1        0.269499        0.181336        0.616583        0.590101   \n",
       "1      2       -0.771319       -0.664547       -1.214896        0.059385   \n",
       "2      3        1.601888        1.000914        1.043142        1.074902   \n",
       "3      4       -0.438803        0.269513        0.834678       -0.642701   \n",
       "4      5        0.122862       -1.187016        1.043753        0.403289   \n",
       "..   ...             ...             ...             ...             ...   \n",
       "495  496        0.162771       -0.863502        1.060396       -0.285125   \n",
       "496  497       -1.853409       -1.344220       -1.043259       -2.193130   \n",
       "497  498        1.765158        2.149623        0.365237        1.181389   \n",
       "498  499       -0.119224        0.752155        1.575431       -1.371880   \n",
       "499  500       -1.017822       -1.982754       -1.982718       -1.667480   \n",
       "\n",
       "     BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n",
       "0          0.309642        0.759479        0.646484        0.301811   \n",
       "1         -0.753830       -0.054308       -1.145725       -1.064132   \n",
       "2          2.328620        1.785143        1.047917        1.976724   \n",
       "3          1.502412       -0.433490        0.748223        1.870233   \n",
       "4          2.416820        0.271279        1.059293       -0.103926   \n",
       "..              ...             ...             ...             ...   \n",
       "495       -0.179507       -0.746345        1.096318       -0.486561   \n",
       "496       -0.642872       -2.138992       -0.976467       -1.863805   \n",
       "497       -0.102844        0.651619        0.235907        0.976983   \n",
       "498       -0.929406        0.115193        1.757926        0.574257   \n",
       "499       -0.086834       -1.822298       -1.879457       -1.887797   \n",
       "\n",
       "     BlendProperty9  BlendProperty10  \n",
       "0         -0.218438         0.336122  \n",
       "1         -0.901618        -0.021733  \n",
       "2          0.675748         2.246820  \n",
       "3          1.048527        -0.937008  \n",
       "4         -0.579997         1.101275  \n",
       "..              ...              ...  \n",
       "495       -1.434873        -0.477653  \n",
       "496       -1.520885        -1.317838  \n",
       "497        0.350661         0.458840  \n",
       "498        0.383757         1.322213  \n",
       "499       -2.307482        -0.229279  \n",
       "\n",
       "[500 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d34bc-8f37-4a63-a5b9-b53afe5fb44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv_3.12)\n",
   "language": "python",
   "name": "myenv_3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
