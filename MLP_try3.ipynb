{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fceb571-d9f5-425d-8fa3-04704cad0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import Any, Literal, NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "import rtdl_num_embeddings  # https://github.com/yandex-research/rtdl-num-embeddings\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import tabm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dadf5395-13fc-4c01-8a37-b09f88ecca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_volume_weighted_component_features(X):\n",
    "    \"\"\"\n",
    "    Computes individual volume-weighted features WjPk = Componentj_fraction * Componentj_Propertyk\n",
    "    for j in 1..5 and k in 1..10 (total 50 features).\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for comp_idx in range(1, 6):  # Components 1–5\n",
    "        for prop_idx in range(1, 11):  # Properties 1–10\n",
    "            vol_col = f'Component{comp_idx}_fraction'\n",
    "            prop_col = f'Component{comp_idx}_Property{prop_idx}'\n",
    "            feat_name = f'W{comp_idx}P{prop_idx}'\n",
    "            features[feat_name] = X[vol_col] * X[prop_col]\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6c88498-9201-4af8-b9e1-4813a3c30210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(\"/pscratch/sd/r/ritesh11/temp_dir/dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"/pscratch/sd/r/ritesh11/temp_dir/dataset/test.csv\")\n",
    "\n",
    "# Separate features and targets\n",
    "feature_cols = train_df.columns[:55]\n",
    "target_cols = train_df.columns[55:]\n",
    "\n",
    "X = train_df[feature_cols].copy()\n",
    "y = train_df[target_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ce243a9-a1e4-4714-9e97-fb3ab97d92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/pscratch/sd/r/ritesh11/temp_dir/NN_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "136e79f2-90fd-4736-a0da-ccf655a26136",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [f\"BlendProperty{i}\" for i in range(1, 11)]\n",
    "target = targets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58590c51-575a-4bbb-8ab8-151f55aa2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "clusters = kmeans.fit_predict(y[[target]])\n",
    "\n",
    "# Stratified sampling on clusters\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=100, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(X, clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00e70308-4ea4-44e0-bcfa-b14fbc667631",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[train_idx]\n",
    "y_train = y.iloc[train_idx][[target]]\n",
    "X_val = X.iloc[val_idx]\n",
    "y_val  = y.iloc[val_idx][[target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57ba356c-60c0-4ec2-a7da-a335b99125f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7b3271d-6a08-47c1-bf2c-d59e4c539805",
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_features = compute_volume_weighted_component_features(X_train)\n",
    "X_train = pd.concat([X_train, blend_features], axis=1)\n",
    "# X_train = pd.DataFrame(\n",
    "#         scaler.fit_transform(X_train),\n",
    "#         columns=X_train.columns,\n",
    "#         index=X_train.index\n",
    "#     )\n",
    "\n",
    "blend_features = compute_volume_weighted_component_features(X_val)\n",
    "X_val = pd.concat([X_val, blend_features], axis=1)\n",
    "# X_val = pd.DataFrame(\n",
    "#         scaler.transform(X_val),\n",
    "#         columns=X_val.columns,\n",
    "#         index=X_val.index\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "675d34bc-8f37-4a63-a5b9-b53afe5fb44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:        CUDA\n",
      "AMP:           True (torch.bfloat16)\n",
      "torch.compile: True\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "Y_train = torch.as_tensor(y_train.values, device=device, dtype=torch.float32)\n",
    "Y_val = torch.as_tensor(y_val.values, device=device, dtype=torch.float32)\n",
    "\n",
    "# 1. Convert DataFrames to NumPy\n",
    "X_train_np = X_train.values\n",
    "X_val_np = X_val.values\n",
    "\n",
    "# 2. Add tiny Gaussian noise to training set to avoid constant features\n",
    "noise = (\n",
    "    np.random.default_rng(0)\n",
    "    .normal(0.0, 1e-5, X_train_np.shape)\n",
    "    .astype(X_train_np.dtype)\n",
    ")\n",
    "\n",
    "# 3. Fit QuantileTransformer on X_train + noise\n",
    "quantile_preproc = sklearn.preprocessing.QuantileTransformer(\n",
    "    n_quantiles=max(min(len(X_train_np) // 30, 1000), 10),\n",
    "    output_distribution='normal',\n",
    "    subsample=10**9,\n",
    ")\n",
    "quantile_preproc.fit(X_train_np + noise)\n",
    "\n",
    "# 4. Transform both X_train and X_val\n",
    "X_train_transformed = quantile_preproc.transform(X_train_np)\n",
    "X_val_transformed = quantile_preproc.transform(X_val_np)\n",
    "\n",
    "# 5. Convert back to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_transformed, dtype=torch.float32, device=device)\n",
    "X_val_tensor = torch.tensor(X_val_transformed, dtype=torch.float32, device=device)\n",
    "\n",
    "# (Optional) replace existing vars\n",
    "X_train = X_train_tensor\n",
    "X_val = X_val_tensor\n",
    "\n",
    "# Label preprocessing.\n",
    "class RegressionLabelStats(NamedTuple):\n",
    "    mean: float\n",
    "    std: float\n",
    "\n",
    "regression_label_stats = RegressionLabelStats(\n",
    "    Y_train.mean().item(), Y_train.std().item()\n",
    ")\n",
    "\n",
    "Y_train = (Y_train - regression_label_stats.mean) / regression_label_stats.std\n",
    "Y_val = (Y_val - regression_label_stats.mean) / regression_label_stats.std\n",
    "\n",
    "amp_dtype = (\n",
    "    torch.bfloat16\n",
    "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "    else torch.float16\n",
    "    if torch.cuda.is_available()\n",
    "    else None\n",
    ")\n",
    "\n",
    "\n",
    "amp_enabled = amp_dtype is not None\n",
    "grad_scaler = torch.cuda.amp.GradScaler() if amp_dtype is torch.float16 else None  # type: ignore\n",
    "\n",
    "# torch.compile\n",
    "compile_model = True\n",
    "\n",
    "# fmt: off\n",
    "print(f'Device:        {device.type.upper()}')\n",
    "print(f'AMP:           {amp_enabled}{f\" ({amp_dtype})\"if amp_enabled else \"\"}')\n",
    "print(f'torch.compile: {compile_model}')\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daa57638-2def-4d41-bc8d-b494f36269f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piecewise-linear embeddings.\n",
    "num_embeddings = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "    rtdl_num_embeddings.compute_bins(X_train, n_bins=48),\n",
    "    d_embedding=16,\n",
    "    activation=False,\n",
    "    version='B',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee071e3b-935a-4b27-83d5-28dcfcf15972",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tabm.TabM.make(\n",
    "    n_num_features=X_train.shape[1],\n",
    "    d_out=1,\n",
    "    num_embeddings=num_embeddings,\n",
    "    # n_blocks = 4,\n",
    "    # k=64,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=3e-4)\n",
    "\n",
    "if compile_model:\n",
    "    # NOTE\n",
    "    # `torch.compile(model, mode=\"reduce-overhead\")` caused issues during training,\n",
    "    # so the `mode` argument is not used.\n",
    "    model = torch.compile(model)\n",
    "    evaluation_mode = torch.no_grad\n",
    "else:\n",
    "    evaluation_mode = torch.inference_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0312ca0-b494-483f-a9d3-566744d70a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): TabM(\n",
       "    (num_module): PiecewiseLinearEmbeddings(\n",
       "      (linear0): LinearEmbeddings()\n",
       "      (impl): _PiecewiseLinearEncodingImpl()\n",
       "      (linear): _NLinear()\n",
       "    )\n",
       "    (ensemble_view): EnsembleView()\n",
       "    (backbone): MLPBackboneBatchEnsemble(\n",
       "      (blocks): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): LinearBatchEnsemble()\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output): LinearEnsemble()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf85f912-7192-4cfb-8a34-d475f7a0dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autocast(device.type, enabled=amp_enabled, dtype=amp_dtype)  # type: ignore[code]\n",
    "def apply_model(data: Tensor, idx: Tensor) -> Tensor:\n",
    "    return (\n",
    "        model(\n",
    "            data[idx],\n",
    "            None,\n",
    "        )\n",
    "        .squeeze(-1)  # Remove the last dimension for regression tasks.\n",
    "        .float()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21cc5c3f-292e-4cb2-8dd5-2941cc8ef7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "share_training_batches = True\n",
    "\n",
    "def loss_fn(y_pred: Tensor, y_true: Tensor) -> Tensor:\n",
    "    \n",
    "    y_pred = y_pred.flatten(0, 1)\n",
    "\n",
    "    if share_training_batches:\n",
    "        # (batch_size,) -> (batch_size * k,)\n",
    "        y_true = y_true.repeat_interleave(model.backbone.k)\n",
    "    else:\n",
    "        # (batch_size, k) -> (batch_size * k,)\n",
    "        y_true = y_true.flatten(0, 1)\n",
    "\n",
    "    return F.mse_loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1595db23-b469-462d-bfd6-15b916becf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@evaluation_mode()\n",
    "def evaluate(x_data: Tensor, y_data: Tensor) -> float:\n",
    "    model.eval()\n",
    "\n",
    "    eval_batch_size = 64\n",
    "    y_pred: np.ndarray = (\n",
    "        torch.cat(\n",
    "            [\n",
    "                apply_model(x_data, idx)\n",
    "                for idx in torch.arange(len(x_data), device=device).split(eval_batch_size)\n",
    "            ]\n",
    "        )\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    assert regression_label_stats is not None\n",
    "    y_pred = y_pred * regression_label_stats.std + regression_label_stats.mean\n",
    "\n",
    "    y_pred = y_pred.mean(1) \n",
    "\n",
    "    y_true = y_data.cpu().numpy()\n",
    "\n",
    "    score = -mean_absolute_percentage_error(y_true, y_pred) \n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63d622cb-14e3-44ff-9732-0277646edba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [epoch] 0   [val] -1.424\n",
      "* [epoch] 0   [val] -1.424\n",
      "* [epoch] 1   [val] -1.318\n",
      "* [epoch] 1   [val] -1.318\n",
      "* [epoch] 2   [val] -1.199\n",
      "* [epoch] 2   [val] -1.199\n",
      "* [epoch] 3   [val] -1.105\n",
      "* [epoch] 3   [val] -1.105\n",
      "* [epoch] 4   [val] -1.055\n",
      "* [epoch] 4   [val] -1.055\n",
      "* [epoch] 5   [val] -0.985\n",
      "* [epoch] 5   [val] -0.985\n",
      "* [epoch] 6   [val] -0.932\n",
      "* [epoch] 6   [val] -0.932\n",
      "* [epoch] 7   [val] -0.901\n",
      "* [epoch] 7   [val] -0.901\n",
      "* [epoch] 8   [val] -0.893\n",
      "* [epoch] 8   [val] -0.893\n",
      "* [epoch] 9   [val] -0.845\n",
      "* [epoch] 9   [val] -0.845\n",
      "* [epoch] 10  [val] -0.802\n",
      "* [epoch] 10  [val] -0.802\n",
      "* [epoch] 11  [val] -0.781\n",
      "* [epoch] 11  [val] -0.781\n",
      "* [epoch] 12  [val] -0.767\n",
      "* [epoch] 12  [val] -0.767\n",
      "* [epoch] 13  [val] -0.724\n",
      "* [epoch] 13  [val] -0.724\n",
      "* [epoch] 14  [val] -0.719\n",
      "* [epoch] 14  [val] -0.719\n",
      "* [epoch] 15  [val] -0.699\n",
      "* [epoch] 15  [val] -0.699\n",
      "* [epoch] 16  [val] -0.690\n",
      "* [epoch] 16  [val] -0.690\n",
      "* [epoch] 17  [val] -0.668\n",
      "* [epoch] 17  [val] -0.668\n",
      "* [epoch] 18  [val] -0.626\n",
      "* [epoch] 18  [val] -0.626\n",
      "* [epoch] 19  [val] -0.626\n",
      "* [epoch] 19  [val] -0.626\n",
      "  [epoch] 20  [val] -0.630\n",
      "  [epoch] 20  [val] -0.630\n",
      "* [epoch] 21  [val] -0.607\n",
      "* [epoch] 21  [val] -0.607\n",
      "  [epoch] 22  [val] -0.614\n",
      "  [epoch] 22  [val] -0.614\n",
      "* [epoch] 23  [val] -0.595\n",
      "* [epoch] 23  [val] -0.595\n",
      "* [epoch] 24  [val] -0.551\n",
      "* [epoch] 24  [val] -0.551\n",
      "  [epoch] 25  [val] -0.555\n",
      "  [epoch] 25  [val] -0.555\n",
      "* [epoch] 26  [val] -0.548\n",
      "* [epoch] 26  [val] -0.548\n",
      "* [epoch] 27  [val] -0.547\n",
      "* [epoch] 27  [val] -0.547\n",
      "* [epoch] 28  [val] -0.537\n",
      "* [epoch] 28  [val] -0.537\n",
      "* [epoch] 29  [val] -0.528\n",
      "* [epoch] 29  [val] -0.528\n",
      "* [epoch] 30  [val] -0.519\n",
      "* [epoch] 30  [val] -0.519\n",
      "* [epoch] 31  [val] -0.499\n",
      "* [epoch] 31  [val] -0.499\n",
      "  [epoch] 32  [val] -0.543\n",
      "  [epoch] 32  [val] -0.543\n",
      "  [epoch] 33  [val] -0.508\n",
      "  [epoch] 33  [val] -0.508\n",
      "* [epoch] 34  [val] -0.498\n",
      "* [epoch] 34  [val] -0.498\n",
      "* [epoch] 35  [val] -0.493\n",
      "* [epoch] 35  [val] -0.493\n",
      "* [epoch] 36  [val] -0.471\n",
      "* [epoch] 36  [val] -0.471\n",
      "* [epoch] 37  [val] -0.466\n",
      "* [epoch] 37  [val] -0.466\n",
      "* [epoch] 38  [val] -0.457\n",
      "* [epoch] 38  [val] -0.457\n",
      "  [epoch] 39  [val] -0.472\n",
      "  [epoch] 39  [val] -0.472\n",
      "  [epoch] 40  [val] -0.460\n",
      "  [epoch] 40  [val] -0.460\n",
      "* [epoch] 41  [val] -0.437\n",
      "* [epoch] 41  [val] -0.437\n",
      "* [epoch] 42  [val] -0.423\n",
      "* [epoch] 42  [val] -0.423\n",
      "  [epoch] 43  [val] -0.445\n",
      "  [epoch] 43  [val] -0.445\n",
      "  [epoch] 44  [val] -0.443\n",
      "  [epoch] 44  [val] -0.443\n",
      "  [epoch] 45  [val] -0.434\n",
      "  [epoch] 45  [val] -0.434\n",
      "  [epoch] 46  [val] -0.447\n",
      "  [epoch] 46  [val] -0.447\n",
      "  [epoch] 47  [val] -0.427\n",
      "  [epoch] 47  [val] -0.427\n",
      "  [epoch] 48  [val] -0.425\n",
      "  [epoch] 48  [val] -0.425\n",
      "  [epoch] 49  [val] -0.440\n",
      "  [epoch] 49  [val] -0.440\n",
      "  [epoch] 50  [val] -0.426\n",
      "  [epoch] 50  [val] -0.426\n",
      "  [epoch] 51  [val] -0.457\n",
      "  [epoch] 51  [val] -0.457\n",
      "  [epoch] 52  [val] -0.432\n",
      "  [epoch] 52  [val] -0.432\n",
      "  [epoch] 53  [val] -0.444\n",
      "  [epoch] 53  [val] -0.444\n",
      "* [epoch] 54  [val] -0.418\n",
      "* [epoch] 54  [val] -0.418\n",
      "  [epoch] 55  [val] -0.423\n",
      "  [epoch] 55  [val] -0.423\n",
      "* [epoch] 56  [val] -0.416\n",
      "* [epoch] 56  [val] -0.416\n",
      "  [epoch] 57  [val] -0.437\n",
      "  [epoch] 57  [val] -0.437\n",
      "  [epoch] 58  [val] -0.448\n",
      "  [epoch] 58  [val] -0.448\n",
      "  [epoch] 59  [val] -0.445\n",
      "  [epoch] 59  [val] -0.445\n",
      "  [epoch] 60  [val] -0.436\n",
      "  [epoch] 60  [val] -0.436\n",
      "  [epoch] 61  [val] -0.432\n",
      "  [epoch] 61  [val] -0.432\n",
      "  [epoch] 62  [val] -0.420\n",
      "  [epoch] 62  [val] -0.420\n",
      "  [epoch] 63  [val] -0.419\n",
      "  [epoch] 63  [val] -0.419\n",
      "  [epoch] 64  [val] -0.421\n",
      "  [epoch] 64  [val] -0.421\n",
      "  [epoch] 65  [val] -0.447\n",
      "  [epoch] 65  [val] -0.447\n",
      "* [epoch] 66  [val] -0.416\n",
      "* [epoch] 66  [val] -0.416\n",
      "  [epoch] 67  [val] -0.446\n",
      "  [epoch] 67  [val] -0.446\n",
      "  [epoch] 68  [val] -0.449\n",
      "  [epoch] 68  [val] -0.449\n",
      "  [epoch] 69  [val] -0.440\n",
      "  [epoch] 69  [val] -0.440\n",
      "* [epoch] 70  [val] -0.413\n",
      "* [epoch] 70  [val] -0.413\n",
      "* [epoch] 71  [val] -0.412\n",
      "* [epoch] 71  [val] -0.412\n",
      "  [epoch] 72  [val] -0.422\n",
      "  [epoch] 72  [val] -0.422\n",
      "  [epoch] 73  [val] -0.417\n",
      "  [epoch] 73  [val] -0.417\n",
      "  [epoch] 74  [val] -0.424\n",
      "  [epoch] 74  [val] -0.424\n",
      "  [epoch] 75  [val] -0.428\n",
      "  [epoch] 75  [val] -0.428\n",
      "  [epoch] 76  [val] -0.430\n",
      "  [epoch] 76  [val] -0.430\n",
      "  [epoch] 77  [val] -0.413\n",
      "  [epoch] 77  [val] -0.413\n",
      "  [epoch] 78  [val] -0.412\n",
      "  [epoch] 78  [val] -0.412\n",
      "* [epoch] 79  [val] -0.407\n",
      "* [epoch] 79  [val] -0.407\n",
      "  [epoch] 80  [val] -0.416\n",
      "  [epoch] 80  [val] -0.416\n",
      "* [epoch] 81  [val] -0.400\n",
      "* [epoch] 81  [val] -0.400\n",
      "  [epoch] 82  [val] -0.408\n",
      "  [epoch] 82  [val] -0.408\n",
      "  [epoch] 83  [val] -0.413\n",
      "  [epoch] 83  [val] -0.413\n",
      "* [epoch] 84  [val] -0.393\n",
      "* [epoch] 84  [val] -0.393\n",
      "  [epoch] 85  [val] -0.403\n",
      "  [epoch] 85  [val] -0.403\n",
      "  [epoch] 86  [val] -0.403\n",
      "  [epoch] 86  [val] -0.403\n",
      "* [epoch] 87  [val] -0.376\n",
      "* [epoch] 87  [val] -0.376\n",
      "* [epoch] 88  [val] -0.372\n",
      "* [epoch] 88  [val] -0.372\n",
      "* [epoch] 89  [val] -0.366\n",
      "* [epoch] 89  [val] -0.366\n",
      "  [epoch] 90  [val] -0.383\n",
      "  [epoch] 90  [val] -0.383\n",
      "  [epoch] 91  [val] -0.380\n",
      "  [epoch] 91  [val] -0.380\n",
      "  [epoch] 92  [val] -0.407\n",
      "  [epoch] 92  [val] -0.407\n",
      "  [epoch] 93  [val] -0.380\n",
      "  [epoch] 93  [val] -0.380\n",
      "  [epoch] 94  [val] -0.400\n",
      "  [epoch] 94  [val] -0.400\n",
      "  [epoch] 95  [val] -0.401\n",
      "  [epoch] 95  [val] -0.401\n",
      "  [epoch] 96  [val] -0.374\n",
      "  [epoch] 96  [val] -0.374\n",
      "  [epoch] 97  [val] -0.392\n",
      "  [epoch] 97  [val] -0.392\n",
      "  [epoch] 98  [val] -0.383\n",
      "  [epoch] 98  [val] -0.383\n",
      "  [epoch] 99  [val] -0.369\n",
      "  [epoch] 99  [val] -0.369\n",
      "  [epoch] 100 [val] -0.399\n",
      "  [epoch] 100 [val] -0.399\n",
      "  [epoch] 101 [val] -0.386\n",
      "  [epoch] 101 [val] -0.386\n",
      "  [epoch] 102 [val] -0.399\n",
      "  [epoch] 102 [val] -0.399\n",
      "* [epoch] 103 [val] -0.363\n",
      "* [epoch] 103 [val] -0.363\n",
      "  [epoch] 104 [val] -0.405\n",
      "  [epoch] 104 [val] -0.405\n",
      "  [epoch] 105 [val] -0.379\n",
      "  [epoch] 105 [val] -0.379\n",
      "  [epoch] 106 [val] -0.395\n",
      "  [epoch] 106 [val] -0.395\n",
      "* [epoch] 107 [val] -0.349\n",
      "* [epoch] 107 [val] -0.349\n",
      "  [epoch] 108 [val] -0.383\n",
      "  [epoch] 108 [val] -0.383\n",
      "  [epoch] 109 [val] -0.373\n",
      "  [epoch] 109 [val] -0.373\n",
      "  [epoch] 110 [val] -0.354\n",
      "  [epoch] 110 [val] -0.354\n",
      "  [epoch] 111 [val] -0.369\n",
      "  [epoch] 111 [val] -0.369\n",
      "  [epoch] 112 [val] -0.364\n",
      "  [epoch] 112 [val] -0.364\n",
      "  [epoch] 113 [val] -0.377\n",
      "  [epoch] 113 [val] -0.377\n",
      "  [epoch] 114 [val] -0.383\n",
      "  [epoch] 114 [val] -0.383\n",
      "  [epoch] 115 [val] -0.385\n",
      "  [epoch] 115 [val] -0.385\n",
      "  [epoch] 116 [val] -0.351\n",
      "  [epoch] 116 [val] -0.351\n",
      "  [epoch] 117 [val] -0.391\n",
      "  [epoch] 117 [val] -0.391\n",
      "  [epoch] 118 [val] -0.404\n",
      "  [epoch] 118 [val] -0.404\n",
      "  [epoch] 119 [val] -0.410\n",
      "  [epoch] 119 [val] -0.410\n",
      "  [epoch] 120 [val] -0.375\n",
      "  [epoch] 120 [val] -0.375\n",
      "  [epoch] 121 [val] -0.382\n",
      "  [epoch] 121 [val] -0.382\n",
      "  [epoch] 122 [val] -0.384\n",
      "  [epoch] 122 [val] -0.384\n",
      "  [epoch] 123 [val] -0.353\n",
      "  [epoch] 123 [val] -0.353\n",
      "  [epoch] 124 [val] -0.376\n",
      "  [epoch] 124 [val] -0.376\n",
      "  [epoch] 125 [val] -0.372\n",
      "  [epoch] 125 [val] -0.372\n",
      "  [epoch] 126 [val] -0.373\n",
      "  [epoch] 126 [val] -0.373\n",
      "  [epoch] 127 [val] -0.361\n",
      "  [epoch] 127 [val] -0.361\n",
      "  [epoch] 128 [val] -0.388\n",
      "  [epoch] 128 [val] -0.388\n",
      "  [epoch] 129 [val] -0.380\n",
      "  [epoch] 129 [val] -0.380\n",
      "  [epoch] 130 [val] -0.371\n",
      "  [epoch] 130 [val] -0.371\n",
      "  [epoch] 131 [val] -0.377\n",
      "  [epoch] 131 [val] -0.377\n",
      "  [epoch] 132 [val] -0.386\n",
      "  [epoch] 132 [val] -0.386\n",
      "  [epoch] 133 [val] -0.406\n",
      "  [epoch] 133 [val] -0.406\n",
      "  [epoch] 134 [val] -0.381\n",
      "  [epoch] 134 [val] -0.381\n",
      "  [epoch] 135 [val] -0.359\n",
      "  [epoch] 135 [val] -0.359\n",
      "  [epoch] 136 [val] -0.366\n",
      "  [epoch] 136 [val] -0.366\n",
      "  [epoch] 137 [val] -0.355\n",
      "  [epoch] 137 [val] -0.355\n",
      "  [epoch] 138 [val] -0.387\n",
      "  [epoch] 138 [val] -0.387\n",
      "  [epoch] 139 [val] -0.384\n",
      "  [epoch] 139 [val] -0.384\n",
      "  [epoch] 140 [val] -0.375\n",
      "  [epoch] 140 [val] -0.375\n",
      "  [epoch] 141 [val] -0.366\n",
      "  [epoch] 141 [val] -0.366\n",
      "  [epoch] 142 [val] -0.372\n",
      "  [epoch] 142 [val] -0.372\n",
      "* [epoch] 143 [val] -0.347\n",
      "* [epoch] 143 [val] -0.347\n",
      "  [epoch] 144 [val] -0.354\n",
      "  [epoch] 144 [val] -0.354\n",
      "  [epoch] 145 [val] -0.405\n",
      "  [epoch] 145 [val] -0.405\n",
      "  [epoch] 146 [val] -0.381\n",
      "  [epoch] 146 [val] -0.381\n",
      "  [epoch] 147 [val] -0.373\n",
      "  [epoch] 147 [val] -0.373\n",
      "  [epoch] 148 [val] -0.395\n",
      "  [epoch] 148 [val] -0.395\n",
      "  [epoch] 149 [val] -0.357\n",
      "  [epoch] 149 [val] -0.357\n",
      "* [epoch] 150 [val] -0.329\n",
      "* [epoch] 150 [val] -0.329\n",
      "  [epoch] 151 [val] -0.412\n",
      "  [epoch] 151 [val] -0.412\n",
      "  [epoch] 152 [val] -0.375\n",
      "  [epoch] 152 [val] -0.375\n",
      "  [epoch] 153 [val] -0.392\n",
      "  [epoch] 153 [val] -0.392\n",
      "  [epoch] 154 [val] -0.375\n",
      "  [epoch] 154 [val] -0.375\n",
      "  [epoch] 155 [val] -0.372\n",
      "  [epoch] 155 [val] -0.372\n",
      "  [epoch] 156 [val] -0.402\n",
      "  [epoch] 156 [val] -0.402\n",
      "* [epoch] 157 [val] -0.329\n",
      "* [epoch] 157 [val] -0.329\n",
      "  [epoch] 158 [val] -0.363\n",
      "  [epoch] 158 [val] -0.363\n",
      "  [epoch] 159 [val] -0.378\n",
      "  [epoch] 159 [val] -0.378\n",
      "  [epoch] 160 [val] -0.361\n",
      "  [epoch] 160 [val] -0.361\n",
      "  [epoch] 161 [val] -0.392\n",
      "  [epoch] 161 [val] -0.392\n",
      "  [epoch] 162 [val] -0.366\n",
      "  [epoch] 162 [val] -0.366\n",
      "  [epoch] 163 [val] -0.380\n",
      "  [epoch] 163 [val] -0.380\n",
      "  [epoch] 164 [val] -0.341\n",
      "  [epoch] 164 [val] -0.341\n",
      "  [epoch] 165 [val] -0.350\n",
      "  [epoch] 165 [val] -0.350\n",
      "  [epoch] 166 [val] -0.374\n",
      "  [epoch] 166 [val] -0.374\n",
      "  [epoch] 167 [val] -0.359\n",
      "  [epoch] 167 [val] -0.359\n",
      "  [epoch] 168 [val] -0.351\n",
      "  [epoch] 168 [val] -0.351\n",
      "  [epoch] 169 [val] -0.343\n",
      "  [epoch] 169 [val] -0.343\n",
      "  [epoch] 170 [val] -0.366\n",
      "  [epoch] 170 [val] -0.366\n",
      "  [epoch] 171 [val] -0.367\n",
      "  [epoch] 171 [val] -0.367\n",
      "  [epoch] 172 [val] -0.396\n",
      "  [epoch] 172 [val] -0.396\n",
      "  [epoch] 173 [val] -0.332\n",
      "  [epoch] 173 [val] -0.332\n",
      "  [epoch] 174 [val] -0.391\n",
      "  [epoch] 174 [val] -0.391\n",
      "  [epoch] 175 [val] -0.381\n",
      "  [epoch] 175 [val] -0.381\n",
      "  [epoch] 176 [val] -0.373\n",
      "  [epoch] 176 [val] -0.373\n",
      "  [epoch] 177 [val] -0.362\n",
      "  [epoch] 177 [val] -0.362\n",
      "  [epoch] 178 [val] -0.363\n",
      "  [epoch] 178 [val] -0.363\n",
      "  [epoch] 179 [val] -0.346\n",
      "  [epoch] 179 [val] -0.346\n",
      "  [epoch] 180 [val] -0.354\n",
      "  [epoch] 180 [val] -0.354\n",
      "  [epoch] 181 [val] -0.335\n",
      "  [epoch] 181 [val] -0.335\n",
      "  [epoch] 182 [val] -0.347\n",
      "  [epoch] 182 [val] -0.347\n",
      "  [epoch] 183 [val] -0.403\n",
      "  [epoch] 183 [val] -0.403\n",
      "  [epoch] 184 [val] -0.349\n",
      "  [epoch] 184 [val] -0.349\n",
      "* [epoch] 185 [val] -0.321\n",
      "* [epoch] 185 [val] -0.321\n",
      "  [epoch] 186 [val] -0.351\n",
      "  [epoch] 186 [val] -0.351\n",
      "  [epoch] 187 [val] -0.374\n",
      "  [epoch] 187 [val] -0.374\n",
      "  [epoch] 188 [val] -0.359\n",
      "  [epoch] 188 [val] -0.359\n",
      "  [epoch] 189 [val] -0.366\n",
      "  [epoch] 189 [val] -0.366\n",
      "  [epoch] 190 [val] -0.356\n",
      "  [epoch] 190 [val] -0.356\n",
      "  [epoch] 191 [val] -0.398\n",
      "  [epoch] 191 [val] -0.398\n",
      "  [epoch] 192 [val] -0.347\n",
      "  [epoch] 192 [val] -0.347\n",
      "  [epoch] 193 [val] -0.329\n",
      "  [epoch] 193 [val] -0.329\n",
      "  [epoch] 194 [val] -0.330\n",
      "  [epoch] 194 [val] -0.330\n",
      "* [epoch] 195 [val] -0.320\n",
      "* [epoch] 195 [val] -0.320\n",
      "  [epoch] 196 [val] -0.359\n",
      "  [epoch] 196 [val] -0.359\n",
      "  [epoch] 197 [val] -0.343\n",
      "  [epoch] 197 [val] -0.343\n",
      "  [epoch] 198 [val] -0.323\n",
      "  [epoch] 198 [val] -0.323\n",
      "  [epoch] 199 [val] -0.355\n",
      "  [epoch] 199 [val] -0.355\n",
      "  [epoch] 200 [val] -0.360\n",
      "  [epoch] 200 [val] -0.360\n",
      "  [epoch] 201 [val] -0.361\n",
      "  [epoch] 201 [val] -0.361\n",
      "  [epoch] 202 [val] -0.362\n",
      "  [epoch] 202 [val] -0.362\n",
      "  [epoch] 203 [val] -0.356\n",
      "  [epoch] 203 [val] -0.356\n",
      "  [epoch] 204 [val] -0.335\n",
      "  [epoch] 204 [val] -0.335\n",
      "* [epoch] 205 [val] -0.283\n",
      "* [epoch] 205 [val] -0.283\n",
      "  [epoch] 206 [val] -0.320\n",
      "  [epoch] 206 [val] -0.320\n",
      "  [epoch] 207 [val] -0.361\n",
      "  [epoch] 207 [val] -0.361\n",
      "  [epoch] 208 [val] -0.325\n",
      "  [epoch] 208 [val] -0.325\n",
      "  [epoch] 209 [val] -0.343\n",
      "  [epoch] 209 [val] -0.343\n",
      "  [epoch] 210 [val] -0.320\n",
      "  [epoch] 210 [val] -0.320\n",
      "  [epoch] 211 [val] -0.317\n",
      "  [epoch] 211 [val] -0.317\n",
      "  [epoch] 212 [val] -0.394\n",
      "  [epoch] 212 [val] -0.394\n",
      "  [epoch] 213 [val] -0.344\n",
      "  [epoch] 213 [val] -0.344\n",
      "  [epoch] 214 [val] -0.317\n",
      "  [epoch] 214 [val] -0.317\n",
      "  [epoch] 215 [val] -0.392\n",
      "  [epoch] 215 [val] -0.392\n",
      "  [epoch] 216 [val] -0.303\n",
      "  [epoch] 216 [val] -0.303\n",
      "  [epoch] 217 [val] -0.314\n",
      "  [epoch] 217 [val] -0.314\n",
      "  [epoch] 218 [val] -0.311\n",
      "  [epoch] 218 [val] -0.311\n",
      "  [epoch] 219 [val] -0.313\n",
      "  [epoch] 219 [val] -0.313\n",
      "  [epoch] 220 [val] -0.381\n",
      "  [epoch] 220 [val] -0.381\n",
      "  [epoch] 221 [val] -0.327\n",
      "  [epoch] 221 [val] -0.327\n",
      "  [epoch] 222 [val] -0.330\n",
      "  [epoch] 222 [val] -0.330\n",
      "  [epoch] 223 [val] -0.352\n",
      "  [epoch] 223 [val] -0.352\n",
      "  [epoch] 224 [val] -0.344\n",
      "  [epoch] 224 [val] -0.344\n",
      "  [epoch] 225 [val] -0.325\n",
      "  [epoch] 225 [val] -0.325\n",
      "  [epoch] 226 [val] -0.315\n",
      "  [epoch] 226 [val] -0.315\n",
      "  [epoch] 227 [val] -0.358\n",
      "  [epoch] 227 [val] -0.358\n",
      "  [epoch] 228 [val] -0.355\n",
      "  [epoch] 228 [val] -0.355\n",
      "  [epoch] 229 [val] -0.296\n",
      "  [epoch] 229 [val] -0.296\n",
      "  [epoch] 230 [val] -0.335\n",
      "  [epoch] 230 [val] -0.335\n",
      "  [epoch] 231 [val] -0.328\n",
      "  [epoch] 231 [val] -0.328\n",
      "  [epoch] 232 [val] -0.332\n",
      "  [epoch] 232 [val] -0.332\n",
      "  [epoch] 233 [val] -0.353\n",
      "  [epoch] 233 [val] -0.353\n",
      "  [epoch] 234 [val] -0.333\n",
      "  [epoch] 234 [val] -0.333\n",
      "  [epoch] 235 [val] -0.344\n",
      "  [epoch] 235 [val] -0.344\n",
      "  [epoch] 236 [val] -0.337\n",
      "  [epoch] 236 [val] -0.337\n",
      "  [epoch] 237 [val] -0.316\n",
      "  [epoch] 237 [val] -0.316\n",
      "  [epoch] 238 [val] -0.331\n",
      "  [epoch] 238 [val] -0.331\n",
      "  [epoch] 239 [val] -0.341\n",
      "  [epoch] 239 [val] -0.341\n",
      "  [epoch] 240 [val] -0.316\n",
      "  [epoch] 240 [val] -0.316\n",
      "  [epoch] 241 [val] -0.329\n",
      "  [epoch] 241 [val] -0.329\n",
      "  [epoch] 242 [val] -0.294\n",
      "  [epoch] 242 [val] -0.294\n",
      "  [epoch] 243 [val] -0.308\n",
      "  [epoch] 243 [val] -0.308\n",
      "  [epoch] 244 [val] -0.356\n",
      "  [epoch] 244 [val] -0.356\n",
      "  [epoch] 245 [val] -0.363\n",
      "  [epoch] 245 [val] -0.363\n",
      "  [epoch] 246 [val] -0.294\n",
      "  [epoch] 246 [val] -0.294\n",
      "  [epoch] 247 [val] -0.350\n",
      "  [epoch] 247 [val] -0.350\n",
      "  [epoch] 248 [val] -0.339\n",
      "  [epoch] 248 [val] -0.339\n",
      "  [epoch] 249 [val] -0.314\n",
      "  [epoch] 249 [val] -0.314\n",
      "  [epoch] 250 [val] -0.354\n",
      "  [epoch] 250 [val] -0.354\n",
      "  [epoch] 251 [val] -0.306\n",
      "  [epoch] 251 [val] -0.306\n",
      "  [epoch] 252 [val] -0.332\n",
      "  [epoch] 252 [val] -0.332\n",
      "  [epoch] 253 [val] -0.308\n",
      "  [epoch] 253 [val] -0.308\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m loss = loss_fn(apply_model(X_train, batch_idx), Y_train[batch_idx])\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grad_scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     optimizer.step()\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1_000_000_000\n",
    "train_size = X_train.shape[0]\n",
    "batch_size = 64\n",
    "epoch_size = math.ceil(train_size / batch_size)\n",
    "\n",
    "epoch = -1\n",
    "metrics = {'val': -math.inf, 'test': -math.inf}\n",
    "\n",
    "\n",
    "def make_checkpoint() -> dict[str, Any]:\n",
    "    return deepcopy(\n",
    "        {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'metrics': metrics,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "best_checkpoint = make_checkpoint()\n",
    "\n",
    "# Early stopping: the training stops if the validation score\n",
    "# does not improve for more than `patience` consecutive epochs.\n",
    "patience = 200\n",
    "remaining_patience = patience\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    batches = (\n",
    "        # Create one standard batch sequence.\n",
    "        torch.randperm(train_size, device=device).split(batch_size)\n",
    "        if share_training_batches\n",
    "        # Create k independent batch sequences.\n",
    "        else (\n",
    "            torch.rand((train_size, model.backbone.k), device=device)\n",
    "            .argsort(dim=0)\n",
    "            .split(batch_size, dim=0)\n",
    "        )\n",
    "    )\n",
    "    for batch_idx in batches:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(apply_model(X_train, batch_idx), Y_train[batch_idx])\n",
    "        if grad_scaler is None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            grad_scaler.scale(loss).backward()  # type: ignore\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "    val_metric = evaluate(X_val, Y_val)\n",
    "    val_score_improved = val_metric > best_checkpoint['metrics']['val']\n",
    "    \n",
    "    metrics[\"val\"] = val_metric  # <-- add this line\n",
    "    \n",
    "    print(\n",
    "        f'{\"*\" if val_score_improved else \" \"}'\n",
    "        f' [epoch] {epoch:<3}'\n",
    "        f' [val] {metrics[\"val\"]:.3f}'\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f'{\"*\" if val_score_improved else \" \"}'\n",
    "        f' [epoch] {epoch:<3}'\n",
    "        f' [val] {metrics[\"val\"]:.3f}'\n",
    "    )\n",
    "\n",
    "    if val_score_improved:\n",
    "        best_checkpoint = make_checkpoint()\n",
    "        remaining_patience = patience\n",
    "    else:\n",
    "        remaining_patience -= 1\n",
    "\n",
    "    if remaining_patience < 0:\n",
    "        break\n",
    "\n",
    "# To make final predictions, load the best checkpoint.\n",
    "model.load_state_dict(best_checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3632b-1c84-4d44-8d64-1fd6f0574fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv_3.12)\n",
   "language": "python",
   "name": "myenv_3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
