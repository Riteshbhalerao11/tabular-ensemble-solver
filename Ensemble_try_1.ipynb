{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d26556e9-070f-4bf3-b928-b778a3444208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from tabpfn_extensions.hpo import TunedTabPFNRegressor\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    RBF,\n",
    "    Matern,\n",
    "    RationalQuadratic,\n",
    "    ExpSineSquared,\n",
    "    DotProduct,\n",
    "    WhiteKernel,\n",
    "    ConstantKernel\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82bb1a1e-eef9-4b43-9746-a92c50c18294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_volume_weighted_component_features(X):\n",
    "    \"\"\"\n",
    "    Computes individual volume-weighted features WjPk = Componentj_fraction * Componentj_Propertyk\n",
    "    for j in 1..5 and k in 1..10 (total 50 features).\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for comp_idx in range(1, 6):  # Components 1–5\n",
    "        for prop_idx in range(1, 11):  # Properties 1–10\n",
    "            vol_col = f'Component{comp_idx}_fraction'\n",
    "            prop_col = f'Component{comp_idx}_Property{prop_idx}'\n",
    "            feat_name = f'W{comp_idx}P{prop_idx}'\n",
    "            features[feat_name] = X[vol_col] * X[prop_col]\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca644d08-246e-41d2-853c-7a91d49fa9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GPR_data(target):\n",
    "    # Load train and val sets\n",
    "    X_train = pd.read_csv(f\"{BASE_PATH}/train/{target}_X.csv\")\n",
    "    y_train = pd.read_csv(f\"{BASE_PATH}/train/{target}_y.csv\")\n",
    "    X_val = pd.read_csv(f\"{BASE_PATH}/val/{target}_X.csv\")\n",
    "    y_val = pd.read_csv(f\"{BASE_PATH}/val/{target}_y.csv\")\n",
    "\n",
    "    # Feature engineering\n",
    "    X_train = pd.concat([X_train, compute_volume_weighted_component_features(X_train)], axis=1)\n",
    "    X_val = pd.concat([X_val, compute_volume_weighted_component_features(X_val)], axis=1)\n",
    "\n",
    "    # Feature selection\n",
    "    df = pd.read_csv(os.path.join(fi_path, f\"{target}.csv\"))\n",
    "    cols = df[df[\"importance\"] > 0.1].iloc[:, 0].tolist()\n",
    "\n",
    "    X_train = X_train[cols]\n",
    "    X_val = X_val[cols]\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    return X_train_scaled, y_train.values.ravel(), X_val_scaled, y_val.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0518777c-ecc0-4d31-88f6-d53b85d7860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(target):\n",
    "    X_train = pd.read_csv(f\"{BASE_PATH}/train/{target}_X.csv\")\n",
    "    y_train = pd.read_csv(f\"{BASE_PATH}/train/{target}_y.csv\")\n",
    "    X_val = pd.read_csv(f\"{BASE_PATH}/val/{target}_X.csv\")\n",
    "    y_val = pd.read_csv(f\"{BASE_PATH}/val/{target}_y.csv\")\n",
    "\n",
    "    X_train = pd.concat([X_train, compute_volume_weighted_component_features(X_train)], axis=1)\n",
    "    X_val = pd.concat([X_val, compute_volume_weighted_component_features(X_val)], axis=1)\n",
    "\n",
    "    return X_train, y_train.values.ravel(), X_val, y_val.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4ac15-5c41-4c0f-a06e-aaa4c6688e4b",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5647dd-2f1d-4f75-8240-586db0e6b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = {'val_loss':[], 'models':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c5a1ef-6164-4b7f-8e44-9eb21d4e6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [f\"BlendProperty{i}\" for i in range(1, 11)]\n",
    "BASE_PATH = \"/pscratch/sd/r/ritesh11/temp_dir/dataset\"\n",
    "model_dir = \"/pscratch/sd/r/ritesh11/temp_dir/NN_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eab0684-9886-402b-b27f-6f532f3db821",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/pscratch/sd/r/ritesh11/temp_dir/dataset/train.csv\")\n",
    "X_test = pd.read_csv(\"/pscratch/sd/r/ritesh11/temp_dir/dataset/test.csv\")\n",
    "X_train = data.iloc[:,:55]\n",
    "y = data.iloc[:,55:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46bc155b-b8ad-4ee8-a01e-29ac6c88f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ca96f2d-5097-4595-bc01-cdddef73305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = []\n",
    "predictors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60a2cfb0-1a41-44a1-a60a-2c2e48743c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in targets:\n",
    "    \n",
    "    # Load data\n",
    "    X_train = pd.read_csv(f\"{BASE_PATH}/train/{t}_X.csv\")\n",
    "    y_train = pd.read_csv(f\"{BASE_PATH}/train/{t}_y.csv\")\n",
    "    X_val = pd.read_csv(f\"{BASE_PATH}/val/{t}_X.csv\")\n",
    "    y_val = pd.read_csv(f\"{BASE_PATH}/val/{t}_y.csv\")\n",
    "    # print(\"Data loaded.\")\n",
    "\n",
    "    # Feature engineering\n",
    "    scaler = StandardScaler()\n",
    "    blend_features_train = compute_volume_weighted_component_features(X_train)\n",
    "    blend_features_val = compute_volume_weighted_component_features(X_val)\n",
    "\n",
    "    X_train = pd.concat([X_train, blend_features_train], axis=1)\n",
    "    X_val = pd.concat([X_val, blend_features_val], axis=1)\n",
    "    # print(\"Volume-weighted features added.\")\n",
    "\n",
    "    # Scaling\n",
    "    X_train = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    X_val = pd.DataFrame(\n",
    "        scaler.transform(X_val),\n",
    "        columns=X_val.columns,\n",
    "        index=X_val.index\n",
    "    )\n",
    "    # print(\"Data scaled.\")\n",
    "\n",
    "    # Load model and evaluate\n",
    "    model_dir = f\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/{t}\"\n",
    "    try:\n",
    "        predictor = TabularPredictor.load(model_dir)\n",
    "        # print(\"Model loaded.\")\n",
    "        \n",
    "        y_pred = predictor.predict(X_val)\n",
    "        loss = mean_absolute_percentage_error(y_val.values.flatten(), y_pred.values)\n",
    "        val_loss.append(loss)\n",
    "        # print(f\"MAPE for {t}: {loss:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to evaluate model for target {t}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe5e78f0-9309-40ac-83ca-706c0e838875",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP['val_loss'] = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b18814-cb45-4617-88d1-ae87a7adc26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in targets:\n",
    "    model_dir = f\"/pscratch/sd/r/ritesh11/temp_dir/NN_models/{t}\"\n",
    "    predictor = TabularPredictor.load(model_dir)\n",
    "    predictors.append(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8576357-4f7f-41ad-b01c-3a154d2f0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP['models'] = predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88e798-49f1-45cb-ab5c-2a9693a771e7",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5362a57a-38b0-4baf-94c2-a5ec02cac57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LASSO = {'data': {}, 'val_loss':[], 'models':[]}\n",
    "RIDGE = {'data': {}, 'val_loss':[], 'models':[]}\n",
    "ELASTIC = {'data': {}, 'val_loss':[], 'models':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b79151f9-c73c-4366-9862-86cdf0c11c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"/pscratch/sd/r/ritesh11/temp_dir/LR_model_outputs\"\n",
    "\n",
    "MODEL_NAMES = [\"LASSOCV\", \"RIDGECV\", \"ELASTICNETCV\"]\n",
    "TARGETS = [f\"BlendProperty{i}\" for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16c8cfb0-9747-4e8e-9b6f-9e0a19e5f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = {model: [] for model in MODEL_NAMES}\n",
    "models = {model: [] for model in MODEL_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "096bb769-029e-4ee2-9ac7-3bb50aaa1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in targets:\n",
    "    # Load data\n",
    "    X_train = pd.read_csv(f\"{BASE_PATH}/train/{t}_X.csv\")\n",
    "    y_train = pd.read_csv(f\"{BASE_PATH}/train/{t}_y.csv\")\n",
    "    X_val = pd.read_csv(f\"{BASE_PATH}/val/{t}_X.csv\")\n",
    "    y_val = pd.read_csv(f\"{BASE_PATH}/val/{t}_y.csv\").values.ravel()\n",
    "    # print(\"Data loaded.\")\n",
    "\n",
    "    for name in MODEL_NAMES:\n",
    "        model_path = os.path.join(SAVE_PATH, f\"{t}_{name}.joblib\")\n",
    "        model = joblib.load(model_path)\n",
    "        preds = model.predict(X_val)\n",
    "        loss = mean_absolute_percentage_error(y_val, preds)\n",
    "        val_loss[name].append(loss)\n",
    "        models[name].append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1fd050e4-65b3-4771-8a68-c9768e3d4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "LASSO['val_loss'] = val_loss['LASSOCV']\n",
    "ELASTIC['val_loss'] = val_loss['ELASTICNETCV']\n",
    "RIDGE['val_loss'] = val_loss['RIDGECV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5494e99-823d-4d36-9c18-cbe0a814519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LASSO['models'] = models['LASSOCV']\n",
    "ELASTIC['models'] = models['ELASTICNETCV']\n",
    "RIDGE['models'] = models['RIDGECV']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07c110-95d4-4bc1-84b8-e30d35949fac",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "daa5c835-ca3d-4559-bb19-2fcb6b7498ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = [f\"BlendProperty{i}\" for i in range(1, 11)]\n",
    "BASE_PATH = \"/pscratch/sd/r/ritesh11/temp_dir/dataset\"\n",
    "model_dir = \"/pscratch/sd/r/ritesh11/temp_dir/XGB_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5dd5995-0b81-49ca-a0d5-1fa8607c4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = {'val_loss':[], 'models':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c42f5c5-5633-4108-b410-233dc5d5475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f41e34e-789c-4dcc-95af-7ebdad522e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:23<00:00,  8.39s/it]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(TARGETS):\n",
    "    X_train, y_train, X_val, y_val = get_data(t)\n",
    "    with open(os.path.join(model_dir, f\"best_params_{t}.json\"), \"r\") as f:\n",
    "        params = json.load(f) \n",
    "    model = xgb.XGBRegressor(**params,device='cuda',tree_method=\"hist\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        verbose=False\n",
    "    )\n",
    "    preds = model.predict(X_val)\n",
    "    loss = mean_absolute_percentage_error(y_val, preds)\n",
    "    val_loss.append(loss)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71625218-6505-4d24-888b-455689e7ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB['val_loss'] = val_loss\n",
    "XGB['models'] = models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ebcd0-f4c8-469f-a2cf-91ff92c9a1da",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e389029b-f5c3-46c3-9a8b-62191f59d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/pscratch/sd/r/ritesh11/temp_dir/LGBM_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "123c0fc1-f54a-4bba-a16d-e2af706d4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM = {'val_loss':[], 'models':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "92e375e4-66b1-4890-90d1-c2c477f240ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02d2abfa-52f8-48c5-aa32-662cfb06336f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(TARGETS):\n",
    "    X_train, y_train, X_val, y_val = get_data(t)\n",
    "    with open(os.path.join(model_dir, f\"best_params_{t}.json\"), \"r\") as f:\n",
    "        params = json.load(f) \n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "    )\n",
    "    preds = model.predict(X_val)\n",
    "    loss = mean_absolute_percentage_error(y_val, preds)\n",
    "    val_loss.append(loss)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6db4d264-be5c-4ab6-af22-b2fbd9642dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM['val_loss'] = val_loss\n",
    "LGBM['models'] = models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1c752-1501-4f35-9d52-1904dcfb822c",
   "metadata": {},
   "source": [
    "# TabPFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42d4d48e-a7ab-49d4-ab2c-279d93fe3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABPFN = {'val_loss':[], 'models':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15725ea2-f74a-4a19-a0bb-4e2344943866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_fn(model, X_val, y_val):\n",
    "    preds = model.predict(X_val)\n",
    "    return mean_absolute_percentage_error(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a329c544-1928-43e9-9f4e-10da61677eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(f\"/pscratch/sd/r/ritesh11/temp_dir/TabPFN_models/{t}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfad564a-69d4-442f-83b2-ab7e8a8d18fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/pscratch/sd/r/ritesh11/temp_dir/TabPFN_models\"\n",
    "val_loss = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08a13e75-d9c0-48de-b91a-7b589c567cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(TARGETS):\n",
    "    X_train, y_train, X_val, y_val = get_data(t)\n",
    "\n",
    "    model = joblib.load(f\"{model_dir}/{t}.pkl\")\n",
    "    preds = model.predict(X_val)\n",
    "    loss = mean_absolute_percentage_error(y_val, preds)\n",
    "    val_loss.append(loss)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31b27014-6912-4ab3-9f8d-0870968aea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABPFN['models'] = models\n",
    "TABPFN['val_loss'] = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c371bdf-ca88-4a46-8ece-316b9446a115",
   "metadata": {},
   "source": [
    "# GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007ddbd-b479-41a7-992a-4b17e123e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPR = {'val_loss':[], 'models':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e42c49ff-0ad2-4438-b569-83425f9f7d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/pscratch/sd/r/ritesh11/temp_dir/dataset\"\n",
    "model_dir = \"/pscratch/sd/r/ritesh11/temp_dir/GPR_models\"\n",
    "fi_path = \"/pscratch/sd/r/ritesh11/temp_dir/feature_importance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "932709d0-abcf-4ca9-b939-30328af2a13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d32af131-e2d5-4f34-ab3b-0e3255e7e6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing target: BlendProperty1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for BlendProperty1: 0.0001\n",
      "\n",
      "Processing target: BlendProperty2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for BlendProperty2: 0.0138\n",
      "\n",
      "Processing target: BlendProperty3\n",
      "MAPE for BlendProperty3: 0.4910\n",
      "\n",
      "Processing target: BlendProperty4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for BlendProperty4: 0.0099\n",
      "\n",
      "Processing target: BlendProperty5\n",
      "MAPE for BlendProperty5: 0.2714\n",
      "\n",
      "Processing target: BlendProperty6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for BlendProperty6: 0.0002\n",
      "\n",
      "Processing target: BlendProperty7\n",
      "MAPE for BlendProperty7: 0.5589\n",
      "\n",
      "Processing target: BlendProperty8\n",
      "MAPE for BlendProperty8: 0.1600\n",
      "\n",
      "Processing target: BlendProperty9\n",
      "MAPE for BlendProperty9: 0.3166\n",
      "\n",
      "Processing target: BlendProperty10\n",
      "MAPE for BlendProperty10: 0.2190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for target in TARGETS:\n",
    "    print(f\"\\nProcessing target: {target}\")\n",
    "\n",
    "    X_train, y_train, X_val, y_val = get_GPR_data(target)\n",
    "\n",
    "    # Load saved best hyperparameters\n",
    "    with open(os.path.join(model_dir, f\"best_params_{target}.json\"), \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    # Convert strings/bools properly\n",
    "    kernel_choice = params[\"kernel\"]\n",
    "    const_scale = float(params[\"const_scale\"])\n",
    "    const_bias = float(params[\"const_bias\"])\n",
    "\n",
    "    # Build the base kernel\n",
    "    if kernel_choice == \"RBF\":\n",
    "        base_kernel = RBF(length_scale_bounds=(1e-5, 1e5))\n",
    "\n",
    "    elif kernel_choice == \"Matern\":\n",
    "        nu = float(params[\"matern_nu\"])\n",
    "        base_kernel = Matern(nu=nu, length_scale_bounds=(1e-5, 1e5))\n",
    "\n",
    "    elif kernel_choice == \"RQ\":\n",
    "        base_kernel = RationalQuadratic(length_scale_bounds=(1e-5, 1e5), alpha_bounds=(1e-5, 1e5))\n",
    "\n",
    "    elif kernel_choice == \"DotProduct\":\n",
    "        base_kernel = DotProduct(sigma_0_bounds=(1e-5, 1e5))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown kernel type: {kernel_choice}\")\n",
    "\n",
    "    # Final kernel composition: scale * kernel + bias + noise\n",
    "    kernel = ConstantKernel(const_scale) * base_kernel\n",
    "    kernel += ConstantKernel(const_bias)\n",
    "    kernel += WhiteKernel(noise_level_bounds=(1e-5, 1e5))\n",
    "\n",
    "    # Final params to GPR\n",
    "    gpr_params = {\n",
    "        \"kernel\": kernel,\n",
    "        \"alpha\": float(params[\"alpha\"]),\n",
    "        \"n_restarts_optimizer\": int(params[\"n_restarts_optimizer\"]),\n",
    "        \"normalize_y\": bool(params[\"normalize_y\"]),\n",
    "        \"random_state\": int(params.get(\"random_state\", 42)),\n",
    "        \"optimizer\": params.get(\"optimizer\", \"fmin_l_bfgs_b\")\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    model = GaussianProcessRegressor(**gpr_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    preds = model.predict(X_val)\n",
    "    score = mean_absolute_percentage_error(y_val, preds)\n",
    "\n",
    "    print(f\"MAPE for {target}: {score:.4f}\")\n",
    "    val_loss.append(score)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34db965e-8c8d-4d56-b679-4e0ac679666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPR = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e048429c-6fb3-40cc-b64a-f3449c3cf7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPR['models'] = models\n",
    "GPR['val_loss'] = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f551506-efed-4713-8bb2-b2757f50ffe8",
   "metadata": {},
   "source": [
    "# ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "469abaae-ebaf-4e1e-8d23-751adad2860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2caedd8d-bba6-4e09-9cb3-6fd909f4c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = {\n",
    "    0 : MLP,\n",
    "    1 : LASSO,\n",
    "    2 : RIDGE,\n",
    "    3 : ELASTIC,\n",
    "    4 : XGB,\n",
    "    5 : LGBM,\n",
    "    6 : TABPFN,\n",
    "    7 : GPR\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ac30c7d0-66d7-443f-b93a-4a3795584e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    weights.append([order[j]['val_loss'][i] for j in range(8)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "91bc1ec0-33b2-4bf1-bb00-c714fa8047a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_matrix = np.array(weights)  # shape: (10, 8)\n",
    "inv_losses = 1.0 / val_loss_matrix\n",
    "normalized_weights = inv_losses / inv_losses.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1667daef-9bb0-4745-9fa3-3f3c15846320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_val, X_val_LR, X_val_mlp, X_val_gpr, y_val, idx, tabpfn_model):\n",
    "    # Individual model predictions\n",
    "    y_pred_mlp     = MLP['models'][idx].predict(X_val_mlp).values\n",
    "    y_pred_lasso   = LASSO['models'][idx].predict(X_val_LR)\n",
    "    y_pred_ridge   = RIDGE['models'][idx].predict(X_val_LR)\n",
    "    y_pred_elastic = ELASTIC['models'][idx].predict(X_val_LR)\n",
    "    y_pred_xgb     = XGB['models'][idx].predict(X_val)\n",
    "    y_pred_lgbm    = LGBM['models'][idx].predict(X_val)\n",
    "    y_pred_tabpfn  = tabpfn_model.predict(X_val)\n",
    "    y_pred_gpr     = GPR['models'][idx].predict(X_val_gpr)\n",
    "\n",
    "    # Suggest weights in [0, 1]\n",
    "    weights = [\n",
    "        trial.suggest_float('w_mlp',     0.0, 1.0),\n",
    "        trial.suggest_float('w_lasso',   0.0, 0.0),\n",
    "        trial.suggest_float('w_ridge',   0.0, 0.0),\n",
    "        trial.suggest_float('w_elastic', 0.0, 0.0),\n",
    "        trial.suggest_float('w_xgb',     0.0, 0.0),\n",
    "        trial.suggest_float('w_lgbm',    0.0, 0.0),\n",
    "        trial.suggest_float('w_tabpfn',  0.0, 1.0),\n",
    "        trial.suggest_float('w_gpr',     0.0, 1.0)\n",
    "    ]\n",
    "\n",
    "    # Normalize weights to sum to 1 (avoid division by zero)\n",
    "    weight_sum = sum(weights)\n",
    "    if weight_sum == 0:\n",
    "        return float(\"inf\")  # Penalize this trial\n",
    "    normed_weights = [w / weight_sum for w in weights]\n",
    "\n",
    "    # Apply weighted ensemble\n",
    "    preds = [y_pred_mlp, y_pred_tabpfn, y_pred_gpr]\n",
    "    \n",
    "    weighted_preds = sum(w * p for w, p in zip(normed_weights, preds))\n",
    "\n",
    "    # Evaluate\n",
    "    score = mean_absolute_percentage_error(y_val, weighted_preds)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c65af2d9-d4a9-4438-9eb9-891205a98b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [f\"BlendProperty{i}\" for i in range(1, 11)]\n",
    "BASE_PATH = \"/pscratch/sd/r/ritesh11/temp_dir/dataset\"\n",
    "tabpfn_dir = \"/pscratch/sd/r/ritesh11/temp_dir/TabPFN_models\"\n",
    "N_TRIALS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0f7b82da-fd2b-466b-8dca-1ff17b149685",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e51ab96b-12b2-495a-bd8a-bae097e1f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a5504a1c-d346-4f14-a98d-73906dd9eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmins = np.argmin(weights, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "17a6edf2-c62e-4f75-bba9-cedb0bc75b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.048122061044873134,\n",
       " 0.09695343906489767,\n",
       " 0.18289210976185172,\n",
       " 0.09670067622134722,\n",
       " 0.6783644979965386,\n",
       " 0.3861311492839096,\n",
       " 0.16757454430321522,\n",
       " 0.21895494520979195]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8a4f2cd4-6428-4a49-8821-83a495af8cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 6, 7, 6, 7, 6, 6, 6, 0])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "797cc5ef-6dc6-46b4-81b6-d5aa746b8c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c25c9ce8f74410ab79add1007f883d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/trial/_trial.py:656: UserWarning: Fixed parameter 'w_lasso' with value 0.004073556139574306 is out of range for distribution FloatDistribution(high=0.0, log=False, low=0.0, step=None).\n",
      "  warnings.warn(\n",
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/trial/_trial.py:656: UserWarning: Fixed parameter 'w_ridge' with value 0.11200150240187758 is out of range for distribution FloatDistribution(high=0.0, log=False, low=0.0, step=None).\n",
      "  warnings.warn(\n",
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/trial/_trial.py:656: UserWarning: Fixed parameter 'w_elastic' with value 0.004100551014941436 is out of range for distribution FloatDistribution(high=0.0, log=False, low=0.0, step=None).\n",
      "  warnings.warn(\n",
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/trial/_trial.py:656: UserWarning: Fixed parameter 'w_xgb' with value 0.0004263958727193267 is out of range for distribution FloatDistribution(high=0.0, log=False, low=0.0, step=None).\n",
      "  warnings.warn(\n",
      "/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/trial/_trial.py:656: UserWarning: Fixed parameter 'w_lgbm' with value 0.0003078064789303852 is out of range for distribution FloatDistribution(high=0.0, log=False, low=0.0, step=None).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-07-11 15:24:53,730] Trial 4 failed with parameters: {} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_730066/802730959.py\", line 52, in <lambda>\n",
      "    lambda trial: objective(trial, X_val ,X_val_LR,X_val_MLP, X_val_gpr, y_val.values.flatten(),i, tabpfn_model),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_730066/1082557424.py\", line 9, in objective\n",
      "    y_pred_tabpfn  = tabpfn_model.predict(X_val)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/tabpfn_extensions/hpo/tuned_tabpfn.py\", line 540, in predict\n",
      "    return self.best_model_.predict(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/tabpfn/regressor.py\", line 649, in predict\n",
      "    for output, config in self.executor_.iter_outputs(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/global/homes/r/ritesh11/.conda/envs/myenv_3.12/lib/python3.12/site-packages/tabpfn/inference.py\", line 301, in iter_outputs\n",
      "    X_train = torch.as_tensor(X_train, dtype=torch.float32, device=device)  # noqa: PLW2901\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-11 15:24:53,732] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[217]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# print(y_val)\u001b[39;00m\n\u001b[32m     50\u001b[39m tabpfn_model = joblib.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtabpfn_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_val_LR\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_val_MLP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_gpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtabpfn_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     56\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m best_params.append(study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[217]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# print(y_val)\u001b[39;00m\n\u001b[32m     50\u001b[39m tabpfn_model = joblib.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtabpfn_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m study.optimize(\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_val_LR\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_val_MLP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_gpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtabpfn_model\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     53\u001b[39m     n_trials=N_TRIALS,\n\u001b[32m     54\u001b[39m     n_jobs=\u001b[32m1\u001b[39m,\n\u001b[32m     55\u001b[39m     show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     56\u001b[39m )\n\u001b[32m     57\u001b[39m best_params.append(study.best_params)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[205]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, X_val, X_val_LR, X_val_mlp, X_val_gpr, y_val, idx, tabpfn_model)\u001b[39m\n\u001b[32m      7\u001b[39m y_pred_xgb     = XGB[\u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m][idx].predict(X_val)\n\u001b[32m      8\u001b[39m y_pred_lgbm    = LGBM[\u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m][idx].predict(X_val)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m y_pred_tabpfn  = \u001b[43mtabpfn_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m y_pred_gpr     = GPR[\u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m][idx].predict(X_val_gpr)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Suggest weights in [0, 1]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/tabpfn_extensions/hpo/tuned_tabpfn.py:540\u001b[39m, in \u001b[36mTunedTabPFNRegressor.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.best_model_, \u001b[33m\"\u001b[39m\u001b[33m_get_tags\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m.best_model_, \u001b[33m\"\u001b[39m\u001b[33mis_fitted_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    537\u001b[39m ):  \u001b[38;5;66;03m# Heuristic check for scikit-learn like estimators\u001b[39;00m\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe underlying best_model_ is not properly fitted.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_model_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/tabpfn/regressor.py:649\u001b[39m, in \u001b[36mTabPFNRegressor.predict\u001b[39m\u001b[34m(self, X, output_type, quantiles)\u001b[39m\n\u001b[32m    646\u001b[39m outputs: \u001b[38;5;28mlist\u001b[39m[torch.Tensor] = []\n\u001b[32m    647\u001b[39m borders: \u001b[38;5;28mlist\u001b[39m[np.ndarray] = []\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecutor_\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_autocast_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRegressorEnsembleConfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmax_temperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv_3.12/lib/python3.12/site-packages/tabpfn/inference.py:301\u001b[39m, in \u001b[36mInferenceEngineCachePreprocessing.iter_outputs\u001b[39m\u001b[34m(self, X, device, autocast, only_return_standard_out)\u001b[39m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.model.type(\u001b[38;5;28mself\u001b[39m.force_inference_dtype)\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m preprocessor, X_train, y_train, config, cat_ix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m    295\u001b[39m     \u001b[38;5;28mself\u001b[39m.preprocessors,\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m.X_trains,\n\u001b[32m   (...)\u001b[39m\u001b[32m    299\u001b[39m     \u001b[38;5;28mself\u001b[39m.cat_ixs,\n\u001b[32m    300\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     X_train = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: PLW2901\u001b[39;00m\n\u001b[32m    303\u001b[39m     X_test = preprocessor.transform(X).X\n\u001b[32m    304\u001b[39m     X_test = torch.as_tensor(X_test, dtype=torch.float32, device=device)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(targets):\n",
    "    \n",
    "    # Load data\n",
    "    X_train = pd.read_csv(f\"{BASE_PATH}/train/{t}_X.csv\")\n",
    "    y_train = pd.read_csv(f\"{BASE_PATH}/train/{t}_y.csv\")\n",
    "    X_val = pd.read_csv(f\"{BASE_PATH}/val/{t}_X.csv\")\n",
    "    y_val = pd.read_csv(f\"{BASE_PATH}/val/{t}_y.csv\")\n",
    "    # print(\"Data loaded.\")\n",
    "    X_val_LR = X_val\n",
    "    # Feature engineering\n",
    "    scaler = StandardScaler()\n",
    "    blend_features_train = compute_volume_weighted_component_features(X_train)\n",
    "    blend_features_val = compute_volume_weighted_component_features(X_val)\n",
    "\n",
    "    X_train = pd.concat([X_train, blend_features_train], axis=1)\n",
    "    X_val = pd.concat([X_val, blend_features_val], axis=1)\n",
    "    \n",
    "    # print(\"Volume-weighted features added.\")\n",
    "\n",
    "    # Scaling\n",
    "    X_train_MLP = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    X_val_MLP = pd.DataFrame(\n",
    "        scaler.transform(X_val),\n",
    "        columns=X_val.columns,\n",
    "        index=X_val.index\n",
    "    )\n",
    "\n",
    "    _, _, X_val_gpr, _ = get_GPR_data(t)\n",
    "    \n",
    "    # Prepare initial weights to enqueue (assumes normalized_weights[i] exists)\n",
    "    weights_to_enqueue = normalized_weights[i]\n",
    "    enqueue_params = {\n",
    "        'w_mlp':     weights_to_enqueue[0],\n",
    "        'w_lasso':   weights_to_enqueue[1],\n",
    "        'w_ridge':   weights_to_enqueue[2],\n",
    "        'w_elastic': weights_to_enqueue[3],\n",
    "        'w_xgb':     weights_to_enqueue[4],\n",
    "        'w_lgbm':    weights_to_enqueue[5],\n",
    "        'w_tabpfn':  weights_to_enqueue[1],\n",
    "        'w_gpr':     weights_to_enqueue[2],\n",
    "    }\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.enqueue_trial(enqueue_params)\n",
    "    # print(y_val)\n",
    "    tabpfn_model = joblib.load(f\"{tabpfn_dir}/{t}.pkl\")\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, X_val ,X_val_LR,X_val_MLP, X_val_gpr, y_val.values.flatten(),i, tabpfn_model),\n",
    "        n_trials=N_TRIALS,\n",
    "        n_jobs=1,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    best_params.append(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee8475-e0a7-43cf-b399-6dfbff9478c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv_3.12)\n",
   "language": "python",
   "name": "myenv_3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
