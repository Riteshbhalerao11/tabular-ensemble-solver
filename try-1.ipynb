{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12375047,"sourceType":"datasetVersion","datasetId":7802891}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:34.527818Z","iopub.execute_input":"2025-07-04T19:25:34.528373Z","iopub.status.idle":"2025-07-04T19:25:34.831967Z","shell.execute_reply.started":"2025-07-04T19:25:34.528349Z","shell.execute_reply":"2025-07-04T19:25:34.831432Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/shell-25/dataset/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:34.833118Z","iopub.execute_input":"2025-07-04T19:25:34.833366Z","iopub.status.idle":"2025-07-04T19:25:34.875834Z","shell.execute_reply.started":"2025-07-04T19:25:34.833349Z","shell.execute_reply":"2025-07-04T19:25:34.875320Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:35.190475Z","iopub.execute_input":"2025-07-04T19:25:35.190706Z","iopub.status.idle":"2025-07-04T19:25:35.213892Z","shell.execute_reply.started":"2025-07-04T19:25:35.190689Z","shell.execute_reply":"2025-07-04T19:25:35.213369Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      Component1_fraction  Component2_fraction  Component3_fraction  \\\n0                    0.21                 0.00                 0.42   \n1                    0.02                 0.33                 0.19   \n2                    0.08                 0.08                 0.18   \n3                    0.25                 0.42                 0.00   \n4                    0.26                 0.16                 0.08   \n...                   ...                  ...                  ...   \n1995                 0.50                 0.12                 0.00   \n1996                 0.19                 0.31                 0.00   \n1997                 0.38                 0.06                 0.14   \n1998                 0.50                 0.16                 0.00   \n1999                 0.00                 0.34                 0.21   \n\n      Component4_fraction  Component5_fraction  Component1_Property1  \\\n0                    0.25                 0.12             -0.021782   \n1                    0.46                 0.00             -0.224339   \n2                    0.50                 0.16              0.457763   \n3                    0.07                 0.26             -0.577734   \n4                    0.50                 0.00              0.120415   \n...                   ...                  ...                   ...   \n1995                 0.26                 0.12              0.279523   \n1996                 0.37                 0.13             -0.887185   \n1997                 0.31                 0.11              0.568978   \n1998                 0.18                 0.16             -0.067453   \n1999                 0.45                 0.00              0.284090   \n\n      Component2_Property1  Component3_Property1  Component4_Property1  \\\n0                 1.981251              0.020036              0.140315   \n1                 1.148036             -1.107840              0.149533   \n2                 0.242591             -0.922492              0.908213   \n3                -0.930826              0.815284              0.447514   \n4                 0.666268             -0.626934              2.725357   \n...                    ...                   ...                   ...   \n1995             -0.054170             -0.391227              0.400222   \n1996              0.610050              0.178606              1.083154   \n1997             -0.196759             -0.646318             -0.980070   \n1998              0.321977             -0.137535              0.238507   \n1999              0.189099             -0.831267             -1.084474   \n\n      Component5_Property1  ...  BlendProperty1  BlendProperty2  \\\n0                 1.032029  ...        0.489143        0.607589   \n1                -0.354000  ...       -1.257481       -1.475283   \n2                 0.972003  ...        1.784349        0.450467   \n3                 0.455717  ...       -0.066422        0.483730   \n4                 0.392259  ...       -0.118913       -1.172398   \n...                    ...  ...             ...             ...   \n1995              1.032029  ...       -0.028366       -0.327297   \n1996             -2.822749  ...       -0.449245        0.156778   \n1997              1.032029  ...        0.029135        0.164890   \n1998              0.017455  ...       -0.232960       -0.464947   \n1999              0.845087  ...       -1.797180       -1.312212   \n\n      BlendProperty3  BlendProperty4  BlendProperty5  BlendProperty6  \\\n0           0.321670       -1.236055        1.601132        1.384662   \n1          -0.437385       -1.402911        0.147941       -1.143244   \n2           0.622687        1.375614       -0.428790        1.161616   \n3          -1.865442       -0.046295       -0.163820       -0.209693   \n4           0.301785       -1.787407       -0.493361       -0.528049   \n...              ...             ...             ...             ...   \n1995       -0.316933       -1.294092       -0.530259       -0.421526   \n1996       -0.367445       -0.938615       -0.577451       -0.209996   \n1997       -0.092942       -1.134490       -0.437479       -0.695636   \n1998        0.112536       -0.793522       -0.811272       -1.194914   \n1999       -0.511896       -1.450066       -0.365154       -1.087937   \n\n      BlendProperty7  BlendProperty8  BlendProperty9  BlendProperty10  \n0           0.305850        0.193460        0.580374        -0.762738  \n1          -0.439171       -1.379041       -1.280989        -0.503625  \n2           0.601289        0.872950        0.660000         2.024576  \n3          -1.840566        0.300293       -0.351336        -1.551914  \n4           0.286344       -0.265192        0.430513         0.735073  \n...              ...             ...             ...              ...  \n1995       -0.320869        0.709627       -0.737244        -0.744289  \n1996       -0.370505       -0.195531       -0.032834         0.269718  \n1997       -0.101073        0.063650        0.624368        -0.477053  \n1998        0.100644        0.760116       -0.751394        -0.857598  \n1999       -0.512119       -0.582473       -0.834879        -0.272462  \n\n[2000 rows x 65 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Component1_fraction</th>\n      <th>Component2_fraction</th>\n      <th>Component3_fraction</th>\n      <th>Component4_fraction</th>\n      <th>Component5_fraction</th>\n      <th>Component1_Property1</th>\n      <th>Component2_Property1</th>\n      <th>Component3_Property1</th>\n      <th>Component4_Property1</th>\n      <th>Component5_Property1</th>\n      <th>...</th>\n      <th>BlendProperty1</th>\n      <th>BlendProperty2</th>\n      <th>BlendProperty3</th>\n      <th>BlendProperty4</th>\n      <th>BlendProperty5</th>\n      <th>BlendProperty6</th>\n      <th>BlendProperty7</th>\n      <th>BlendProperty8</th>\n      <th>BlendProperty9</th>\n      <th>BlendProperty10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.21</td>\n      <td>0.00</td>\n      <td>0.42</td>\n      <td>0.25</td>\n      <td>0.12</td>\n      <td>-0.021782</td>\n      <td>1.981251</td>\n      <td>0.020036</td>\n      <td>0.140315</td>\n      <td>1.032029</td>\n      <td>...</td>\n      <td>0.489143</td>\n      <td>0.607589</td>\n      <td>0.321670</td>\n      <td>-1.236055</td>\n      <td>1.601132</td>\n      <td>1.384662</td>\n      <td>0.305850</td>\n      <td>0.193460</td>\n      <td>0.580374</td>\n      <td>-0.762738</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02</td>\n      <td>0.33</td>\n      <td>0.19</td>\n      <td>0.46</td>\n      <td>0.00</td>\n      <td>-0.224339</td>\n      <td>1.148036</td>\n      <td>-1.107840</td>\n      <td>0.149533</td>\n      <td>-0.354000</td>\n      <td>...</td>\n      <td>-1.257481</td>\n      <td>-1.475283</td>\n      <td>-0.437385</td>\n      <td>-1.402911</td>\n      <td>0.147941</td>\n      <td>-1.143244</td>\n      <td>-0.439171</td>\n      <td>-1.379041</td>\n      <td>-1.280989</td>\n      <td>-0.503625</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.08</td>\n      <td>0.08</td>\n      <td>0.18</td>\n      <td>0.50</td>\n      <td>0.16</td>\n      <td>0.457763</td>\n      <td>0.242591</td>\n      <td>-0.922492</td>\n      <td>0.908213</td>\n      <td>0.972003</td>\n      <td>...</td>\n      <td>1.784349</td>\n      <td>0.450467</td>\n      <td>0.622687</td>\n      <td>1.375614</td>\n      <td>-0.428790</td>\n      <td>1.161616</td>\n      <td>0.601289</td>\n      <td>0.872950</td>\n      <td>0.660000</td>\n      <td>2.024576</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.25</td>\n      <td>0.42</td>\n      <td>0.00</td>\n      <td>0.07</td>\n      <td>0.26</td>\n      <td>-0.577734</td>\n      <td>-0.930826</td>\n      <td>0.815284</td>\n      <td>0.447514</td>\n      <td>0.455717</td>\n      <td>...</td>\n      <td>-0.066422</td>\n      <td>0.483730</td>\n      <td>-1.865442</td>\n      <td>-0.046295</td>\n      <td>-0.163820</td>\n      <td>-0.209693</td>\n      <td>-1.840566</td>\n      <td>0.300293</td>\n      <td>-0.351336</td>\n      <td>-1.551914</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.26</td>\n      <td>0.16</td>\n      <td>0.08</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.120415</td>\n      <td>0.666268</td>\n      <td>-0.626934</td>\n      <td>2.725357</td>\n      <td>0.392259</td>\n      <td>...</td>\n      <td>-0.118913</td>\n      <td>-1.172398</td>\n      <td>0.301785</td>\n      <td>-1.787407</td>\n      <td>-0.493361</td>\n      <td>-0.528049</td>\n      <td>0.286344</td>\n      <td>-0.265192</td>\n      <td>0.430513</td>\n      <td>0.735073</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>0.50</td>\n      <td>0.12</td>\n      <td>0.00</td>\n      <td>0.26</td>\n      <td>0.12</td>\n      <td>0.279523</td>\n      <td>-0.054170</td>\n      <td>-0.391227</td>\n      <td>0.400222</td>\n      <td>1.032029</td>\n      <td>...</td>\n      <td>-0.028366</td>\n      <td>-0.327297</td>\n      <td>-0.316933</td>\n      <td>-1.294092</td>\n      <td>-0.530259</td>\n      <td>-0.421526</td>\n      <td>-0.320869</td>\n      <td>0.709627</td>\n      <td>-0.737244</td>\n      <td>-0.744289</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>0.19</td>\n      <td>0.31</td>\n      <td>0.00</td>\n      <td>0.37</td>\n      <td>0.13</td>\n      <td>-0.887185</td>\n      <td>0.610050</td>\n      <td>0.178606</td>\n      <td>1.083154</td>\n      <td>-2.822749</td>\n      <td>...</td>\n      <td>-0.449245</td>\n      <td>0.156778</td>\n      <td>-0.367445</td>\n      <td>-0.938615</td>\n      <td>-0.577451</td>\n      <td>-0.209996</td>\n      <td>-0.370505</td>\n      <td>-0.195531</td>\n      <td>-0.032834</td>\n      <td>0.269718</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>0.38</td>\n      <td>0.06</td>\n      <td>0.14</td>\n      <td>0.31</td>\n      <td>0.11</td>\n      <td>0.568978</td>\n      <td>-0.196759</td>\n      <td>-0.646318</td>\n      <td>-0.980070</td>\n      <td>1.032029</td>\n      <td>...</td>\n      <td>0.029135</td>\n      <td>0.164890</td>\n      <td>-0.092942</td>\n      <td>-1.134490</td>\n      <td>-0.437479</td>\n      <td>-0.695636</td>\n      <td>-0.101073</td>\n      <td>0.063650</td>\n      <td>0.624368</td>\n      <td>-0.477053</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>0.50</td>\n      <td>0.16</td>\n      <td>0.00</td>\n      <td>0.18</td>\n      <td>0.16</td>\n      <td>-0.067453</td>\n      <td>0.321977</td>\n      <td>-0.137535</td>\n      <td>0.238507</td>\n      <td>0.017455</td>\n      <td>...</td>\n      <td>-0.232960</td>\n      <td>-0.464947</td>\n      <td>0.112536</td>\n      <td>-0.793522</td>\n      <td>-0.811272</td>\n      <td>-1.194914</td>\n      <td>0.100644</td>\n      <td>0.760116</td>\n      <td>-0.751394</td>\n      <td>-0.857598</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>0.00</td>\n      <td>0.34</td>\n      <td>0.21</td>\n      <td>0.45</td>\n      <td>0.00</td>\n      <td>0.284090</td>\n      <td>0.189099</td>\n      <td>-0.831267</td>\n      <td>-1.084474</td>\n      <td>0.845087</td>\n      <td>...</td>\n      <td>-1.797180</td>\n      <td>-1.312212</td>\n      <td>-0.511896</td>\n      <td>-1.450066</td>\n      <td>-0.365154</td>\n      <td>-1.087937</td>\n      <td>-0.512119</td>\n      <td>-0.582473</td>\n      <td>-0.834879</td>\n      <td>-0.272462</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows Ã— 65 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# !pip install autogluon","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:36.125444Z","iopub.execute_input":"2025-07-04T19:25:36.126091Z","iopub.status.idle":"2025-07-04T19:25:36.129140Z","shell.execute_reply.started":"2025-07-04T19:25:36.126070Z","shell.execute_reply":"2025-07-04T19:25:36.128489Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom autogluon.tabular import TabularPredictor\n\n# Load data\ntrain_df = pd.read_csv(\"/kaggle/input/shell-25/dataset/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/shell-25/dataset/test.csv\")\n\n# Separate features and targets\nfeature_cols = train_df.columns[:55]\ntarget_cols = train_df.columns[55:]\n\nX = train_df[feature_cols].copy()\ny = train_df[target_cols].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:36.500402Z","iopub.execute_input":"2025-07-04T19:25:36.500853Z","iopub.status.idle":"2025-07-04T19:25:37.428223Z","shell.execute_reply.started":"2025-07-04T19:25:36.500834Z","shell.execute_reply":"2025-07-04T19:25:37.427398Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:38.875444Z","iopub.execute_input":"2025-07-04T19:25:38.875793Z","iopub.status.idle":"2025-07-04T19:25:38.880849Z","shell.execute_reply.started":"2025-07-04T19:25:38.875769Z","shell.execute_reply":"2025-07-04T19:25:38.880284Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['Component1_fraction', 'Component2_fraction', 'Component3_fraction',\n       'Component4_fraction', 'Component5_fraction', 'Component1_Property1',\n       'Component2_Property1', 'Component3_Property1', 'Component4_Property1',\n       'Component5_Property1', 'Component1_Property2', 'Component2_Property2',\n       'Component3_Property2', 'Component4_Property2', 'Component5_Property2',\n       'Component1_Property3', 'Component2_Property3', 'Component3_Property3',\n       'Component4_Property3', 'Component5_Property3', 'Component1_Property4',\n       'Component2_Property4', 'Component3_Property4', 'Component4_Property4',\n       'Component5_Property4', 'Component1_Property5', 'Component2_Property5',\n       'Component3_Property5', 'Component4_Property5', 'Component5_Property5',\n       'Component1_Property6', 'Component2_Property6', 'Component3_Property6',\n       'Component4_Property6', 'Component5_Property6', 'Component1_Property7',\n       'Component2_Property7', 'Component3_Property7', 'Component4_Property7',\n       'Component5_Property7', 'Component1_Property8', 'Component2_Property8',\n       'Component3_Property8', 'Component4_Property8', 'Component5_Property8',\n       'Component1_Property9', 'Component2_Property9', 'Component3_Property9',\n       'Component4_Property9', 'Component5_Property9', 'Component1_Property10',\n       'Component2_Property10', 'Component3_Property10',\n       'Component4_Property10', 'Component5_Property10'],\n      dtype='object')"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def compute_volume_weighted_blend_features(X):\n    \"\"\"\n    Computes volume-weighted blend-level properties for each of the 10 properties.\n    \"\"\"\n    weighted_props = {}\n    for prop_idx in range(1, 11):  # Property1 to Property10\n        blend_prop = 0\n        for comp_idx in range(1, 6):  # Component1 to Component5\n            vol_col = f'Component{comp_idx}_fraction'\n            prop_col = f'Component{comp_idx}_Property{prop_idx}'\n            blend_prop += X[vol_col] * X[prop_col]\n        weighted_props[f'BlendEst_Property{prop_idx}'] = blend_prop / 100.0\n    return pd.DataFrame(weighted_props)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:39.135821Z","iopub.execute_input":"2025-07-04T19:25:39.136013Z","iopub.status.idle":"2025-07-04T19:25:39.140777Z","shell.execute_reply.started":"2025-07-04T19:25:39.135997Z","shell.execute_reply":"2025-07-04T19:25:39.140061Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Compute and append new blend-level features\nblend_features = compute_volume_weighted_blend_features(X)\nX = pd.concat([X, blend_features], axis=1)\n\n# Do the same for test data\nX_test = test_df[X.columns[:55]]  # assumes same structure\nblend_features_test = compute_volume_weighted_blend_features(X_test)\nX_test = pd.concat([X_test, blend_features_test], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:39.555370Z","iopub.execute_input":"2025-07-04T19:25:39.555898Z","iopub.status.idle":"2025-07-04T19:25:39.582546Z","shell.execute_reply.started":"2025-07-04T19:25:39.555881Z","shell.execute_reply":"2025-07-04T19:25:39.581897Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"X_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:42.195520Z","iopub.execute_input":"2025-07-04T19:25:42.196077Z","iopub.status.idle":"2025-07-04T19:25:42.216026Z","shell.execute_reply.started":"2025-07-04T19:25:42.196050Z","shell.execute_reply":"2025-07-04T19:25:42.215372Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"     Component1_fraction  Component2_fraction  Component3_fraction  \\\n0                   0.18                 0.05                 0.32   \n1                   0.00                 0.50                 0.00   \n2                   0.16                 0.00                 0.17   \n3                   0.50                 0.00                 0.17   \n4                   0.00                 0.00                 0.50   \n..                   ...                  ...                  ...   \n495                 0.44                 0.01                 0.08   \n496                 0.19                 0.47                 0.03   \n497                 0.43                 0.01                 0.12   \n498                 0.03                 0.04                 0.42   \n499                 0.00                 0.50                 0.00   \n\n     Component4_fraction  Component5_fraction  Component1_Property1  \\\n0                   0.37                 0.08             -0.177804   \n1                   0.37                 0.13              2.501354   \n2                   0.50                 0.17              1.547324   \n3                   0.16                 0.17             -0.424427   \n4                   0.50                 0.00             -0.187062   \n..                   ...                  ...                   ...   \n495                 0.41                 0.06              1.036797   \n496                 0.23                 0.08             -1.305137   \n497                 0.21                 0.23              0.806590   \n498                 0.42                 0.09             -0.792140   \n499                 0.50                 0.00             -0.327778   \n\n     Component2_Property1  Component3_Property1  Component4_Property1  \\\n0               -0.741219              0.769821             -0.877069   \n1                0.177344             -0.498739             -0.196742   \n2                0.891479              0.030627             -0.368678   \n3                1.016862             -1.182979             -0.854225   \n4               -0.762173             -0.473660              2.074087   \n..                    ...                   ...                   ...   \n495              1.415667              0.793302             -0.446630   \n496             -1.520941             -0.989537              0.903203   \n497              0.607324              0.359058              0.283394   \n498              0.674275             -1.783487              0.848296   \n499              0.248042             -1.199065              1.845241   \n\n     Component5_Property1  ...  BlendEst_Property1  BlendEst_Property2  \\\n0                0.602809  ...           -0.000990            0.000756   \n1               -1.943463  ...           -0.002368            0.001123   \n2               -0.294728  ...            0.000183           -0.002463   \n3               -0.830186  ...           -0.006911            0.001502   \n4                0.756849  ...            0.008002           -0.014748   \n..                    ...  ...                 ...                 ...   \n495              0.395524  ...            0.003744           -0.004471   \n496              1.032029  ...           -0.007022            0.003248   \n497              1.032029  ...            0.006929            0.013013   \n498              0.164798  ...           -0.003747           -0.002723   \n499              0.772672  ...            0.010466           -0.006630   \n\n     BlendEst_Property3  BlendEst_Property4  BlendEst_Property5  \\\n0             -0.001855            0.009188            0.004174   \n1              0.006133            0.006882           -0.009066   \n2              0.006907           -0.005549            0.010019   \n3             -0.004316           -0.009140            0.004817   \n4              0.006398            0.008344           -0.000343   \n..                  ...                 ...                 ...   \n495           -0.003875            0.000944            0.006869   \n496            0.001928           -0.011361           -0.004362   \n497           -0.001846            0.000177            0.005718   \n498           -0.008590           -0.017343           -0.008161   \n499            0.006708           -0.001863           -0.000364   \n\n     BlendEst_Property6  BlendEst_Property7  BlendEst_Property8  \\\n0              0.004803           -0.006113            0.001229   \n1              0.004678            0.010493            0.000283   \n2              0.004685           -0.005192            0.005401   \n3             -0.006442           -0.001058            0.014779   \n4             -0.000206            0.000020           -0.005766   \n..                  ...                 ...                 ...   \n495           -0.003595            0.009048           -0.000716   \n496           -0.010684            0.006268            0.003925   \n497           -0.001797           -0.006263            0.003280   \n498           -0.003805            0.008810            0.000204   \n499           -0.003045           -0.004165           -0.002556   \n\n     BlendEst_Property9  BlendEst_Property10  \n0              0.000072            -0.000099  \n1             -0.010357             0.004234  \n2             -0.004572            -0.002365  \n3             -0.005335            -0.001220  \n4             -0.001206            -0.001873  \n..                  ...                  ...  \n495           -0.017260            -0.010985  \n496           -0.007330             0.009645  \n497           -0.009896             0.002967  \n498           -0.002436             0.006742  \n499           -0.004720             0.002047  \n\n[500 rows x 65 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Component1_fraction</th>\n      <th>Component2_fraction</th>\n      <th>Component3_fraction</th>\n      <th>Component4_fraction</th>\n      <th>Component5_fraction</th>\n      <th>Component1_Property1</th>\n      <th>Component2_Property1</th>\n      <th>Component3_Property1</th>\n      <th>Component4_Property1</th>\n      <th>Component5_Property1</th>\n      <th>...</th>\n      <th>BlendEst_Property1</th>\n      <th>BlendEst_Property2</th>\n      <th>BlendEst_Property3</th>\n      <th>BlendEst_Property4</th>\n      <th>BlendEst_Property5</th>\n      <th>BlendEst_Property6</th>\n      <th>BlendEst_Property7</th>\n      <th>BlendEst_Property8</th>\n      <th>BlendEst_Property9</th>\n      <th>BlendEst_Property10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.18</td>\n      <td>0.05</td>\n      <td>0.32</td>\n      <td>0.37</td>\n      <td>0.08</td>\n      <td>-0.177804</td>\n      <td>-0.741219</td>\n      <td>0.769821</td>\n      <td>-0.877069</td>\n      <td>0.602809</td>\n      <td>...</td>\n      <td>-0.000990</td>\n      <td>0.000756</td>\n      <td>-0.001855</td>\n      <td>0.009188</td>\n      <td>0.004174</td>\n      <td>0.004803</td>\n      <td>-0.006113</td>\n      <td>0.001229</td>\n      <td>0.000072</td>\n      <td>-0.000099</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.37</td>\n      <td>0.13</td>\n      <td>2.501354</td>\n      <td>0.177344</td>\n      <td>-0.498739</td>\n      <td>-0.196742</td>\n      <td>-1.943463</td>\n      <td>...</td>\n      <td>-0.002368</td>\n      <td>0.001123</td>\n      <td>0.006133</td>\n      <td>0.006882</td>\n      <td>-0.009066</td>\n      <td>0.004678</td>\n      <td>0.010493</td>\n      <td>0.000283</td>\n      <td>-0.010357</td>\n      <td>0.004234</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.16</td>\n      <td>0.00</td>\n      <td>0.17</td>\n      <td>0.50</td>\n      <td>0.17</td>\n      <td>1.547324</td>\n      <td>0.891479</td>\n      <td>0.030627</td>\n      <td>-0.368678</td>\n      <td>-0.294728</td>\n      <td>...</td>\n      <td>0.000183</td>\n      <td>-0.002463</td>\n      <td>0.006907</td>\n      <td>-0.005549</td>\n      <td>0.010019</td>\n      <td>0.004685</td>\n      <td>-0.005192</td>\n      <td>0.005401</td>\n      <td>-0.004572</td>\n      <td>-0.002365</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.17</td>\n      <td>0.16</td>\n      <td>0.17</td>\n      <td>-0.424427</td>\n      <td>1.016862</td>\n      <td>-1.182979</td>\n      <td>-0.854225</td>\n      <td>-0.830186</td>\n      <td>...</td>\n      <td>-0.006911</td>\n      <td>0.001502</td>\n      <td>-0.004316</td>\n      <td>-0.009140</td>\n      <td>0.004817</td>\n      <td>-0.006442</td>\n      <td>-0.001058</td>\n      <td>0.014779</td>\n      <td>-0.005335</td>\n      <td>-0.001220</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>-0.187062</td>\n      <td>-0.762173</td>\n      <td>-0.473660</td>\n      <td>2.074087</td>\n      <td>0.756849</td>\n      <td>...</td>\n      <td>0.008002</td>\n      <td>-0.014748</td>\n      <td>0.006398</td>\n      <td>0.008344</td>\n      <td>-0.000343</td>\n      <td>-0.000206</td>\n      <td>0.000020</td>\n      <td>-0.005766</td>\n      <td>-0.001206</td>\n      <td>-0.001873</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>0.44</td>\n      <td>0.01</td>\n      <td>0.08</td>\n      <td>0.41</td>\n      <td>0.06</td>\n      <td>1.036797</td>\n      <td>1.415667</td>\n      <td>0.793302</td>\n      <td>-0.446630</td>\n      <td>0.395524</td>\n      <td>...</td>\n      <td>0.003744</td>\n      <td>-0.004471</td>\n      <td>-0.003875</td>\n      <td>0.000944</td>\n      <td>0.006869</td>\n      <td>-0.003595</td>\n      <td>0.009048</td>\n      <td>-0.000716</td>\n      <td>-0.017260</td>\n      <td>-0.010985</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>0.19</td>\n      <td>0.47</td>\n      <td>0.03</td>\n      <td>0.23</td>\n      <td>0.08</td>\n      <td>-1.305137</td>\n      <td>-1.520941</td>\n      <td>-0.989537</td>\n      <td>0.903203</td>\n      <td>1.032029</td>\n      <td>...</td>\n      <td>-0.007022</td>\n      <td>0.003248</td>\n      <td>0.001928</td>\n      <td>-0.011361</td>\n      <td>-0.004362</td>\n      <td>-0.010684</td>\n      <td>0.006268</td>\n      <td>0.003925</td>\n      <td>-0.007330</td>\n      <td>0.009645</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>0.43</td>\n      <td>0.01</td>\n      <td>0.12</td>\n      <td>0.21</td>\n      <td>0.23</td>\n      <td>0.806590</td>\n      <td>0.607324</td>\n      <td>0.359058</td>\n      <td>0.283394</td>\n      <td>1.032029</td>\n      <td>...</td>\n      <td>0.006929</td>\n      <td>0.013013</td>\n      <td>-0.001846</td>\n      <td>0.000177</td>\n      <td>0.005718</td>\n      <td>-0.001797</td>\n      <td>-0.006263</td>\n      <td>0.003280</td>\n      <td>-0.009896</td>\n      <td>0.002967</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>0.03</td>\n      <td>0.04</td>\n      <td>0.42</td>\n      <td>0.42</td>\n      <td>0.09</td>\n      <td>-0.792140</td>\n      <td>0.674275</td>\n      <td>-1.783487</td>\n      <td>0.848296</td>\n      <td>0.164798</td>\n      <td>...</td>\n      <td>-0.003747</td>\n      <td>-0.002723</td>\n      <td>-0.008590</td>\n      <td>-0.017343</td>\n      <td>-0.008161</td>\n      <td>-0.003805</td>\n      <td>0.008810</td>\n      <td>0.000204</td>\n      <td>-0.002436</td>\n      <td>0.006742</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>-0.327778</td>\n      <td>0.248042</td>\n      <td>-1.199065</td>\n      <td>1.845241</td>\n      <td>0.772672</td>\n      <td>...</td>\n      <td>0.010466</td>\n      <td>-0.006630</td>\n      <td>0.006708</td>\n      <td>-0.001863</td>\n      <td>-0.000364</td>\n      <td>-0.003045</td>\n      <td>-0.004165</td>\n      <td>-0.002556</td>\n      <td>-0.004720</td>\n      <td>0.002047</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows Ã— 65 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# After computing blend_features\nfor i in range(1, 11):\n    corr = np.corrcoef(blend_features[f'BlendEst_Property{i}'], train_df[f'BlendProperty{i}'])[0, 1]\n    print(f\"Corr(Est_Property{i}, True_BlendProperty{i}) = {corr:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:42.375965Z","iopub.execute_input":"2025-07-04T19:25:42.376182Z","iopub.status.idle":"2025-07-04T19:25:42.384611Z","shell.execute_reply.started":"2025-07-04T19:25:42.376165Z","shell.execute_reply":"2025-07-04T19:25:42.383952Z"}},"outputs":[{"name":"stdout","text":"Corr(Est_Property1, True_BlendProperty1) = 0.475\nCorr(Est_Property2, True_BlendProperty2) = 0.483\nCorr(Est_Property3, True_BlendProperty3) = -0.029\nCorr(Est_Property4, True_BlendProperty4) = 0.510\nCorr(Est_Property5, True_BlendProperty5) = 0.250\nCorr(Est_Property6, True_BlendProperty6) = 0.678\nCorr(Est_Property7, True_BlendProperty7) = 0.372\nCorr(Est_Property8, True_BlendProperty8) = 0.507\nCorr(Est_Property9, True_BlendProperty9) = 0.446\nCorr(Est_Property10, True_BlendProperty10) = 0.311\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"metric_code = \"\"\"\nimport numpy as np\nfrom sklearn.metrics import mean_absolute_percentage_error\n\ndef safe_sklearn_mape(y_true, y_pred):\n    \\\"\"\"\n    Safe version of Scikit-learn's MAPE that avoids division-by-zero errors\n    by replacing small y_true values with epsilon.\n    \\\"\"\"\n    epsilon = 1e-6\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    y_true_safe = np.where(np.abs(y_true) < epsilon, epsilon, y_true)\n    return mean_absolute_percentage_error(y_true_safe, y_pred)\n\"\"\"\n\n# Save to file\nwith open(\"mymetrics.py\", \"w\") as f:\n    f.write(metric_code.strip())\n\nprint(\"âœ… `mymetrics.py` has been created in the current directory.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:42.660462Z","iopub.execute_input":"2025-07-04T19:25:42.660866Z","iopub.status.idle":"2025-07-04T19:25:42.665310Z","shell.execute_reply.started":"2025-07-04T19:25:42.660850Z","shell.execute_reply":"2025-07-04T19:25:42.664801Z"}},"outputs":[{"name":"stdout","text":"âœ… `mymetrics.py` has been created in the current directory.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from autogluon.core.metrics import make_scorer\nfrom mymetrics import safe_sklearn_mape\n\n# Register for AutoGluon\nmape_metric = make_scorer(\n    name='sklearn_safe_mape',\n    score_func=safe_sklearn_mape,\n    optimum=0,\n    greater_is_better=False,\n    needs_proba=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:43.159583Z","iopub.execute_input":"2025-07-04T19:25:43.160119Z","iopub.status.idle":"2025-07-04T19:25:43.164555Z","shell.execute_reply.started":"2025-07-04T19:25:43.160102Z","shell.execute_reply":"2025-07-04T19:25:43.163910Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import os\nimport shutil\nimport time\nfrom autogluon.tabular import TabularPredictor\nfrom tqdm import tqdm\n\nmodel_base_dir = \"autogluon_models\"\nos.makedirs(model_base_dir, exist_ok=True)\n\npredictors = {}\ntime_limit = 6000  # seconds per model\n\nfor target in y.columns:\n    model_path = os.path.join(model_base_dir, target)\n\n    # ðŸ§¹ Clean up any existing model directory\n    if os.path.exists(model_path):\n        print(f\"\\nðŸ§¹ Clearing old model for: {target}\")\n        shutil.rmtree(model_path)\n\n    print(f\"\\nðŸš€ Starting training for: {target}\")\n    start = time.time()\n\n    train_data = pd.concat([X, y[[target]]], axis=1)\n\n    predictor = TabularPredictor(\n        label=target,\n        path=model_path,\n        eval_metric=mape_metric,\n        verbosity=2\n    ).fit(\n        train_data=train_data,\n        presets='best_quality',\n        time_limit=time_limit,\n        num_bag_folds=5,\n        num_stack_levels=1,\n        # ag_args_fit={\"num_gpus\": \"auto\"}\n    )\n\n    predictors[target] = predictor\n\n    # Leaderboard\n    print(f\"\\nðŸ“Š Leaderboard for {target}\")\n    print(predictor.leaderboard(silent=True))\n\n    # Training time\n    elapsed = time.time() - start\n    print(f\"âœ… Finished training {target} in {elapsed:.2f} sec\")\n\n    # Model size\n    total_size = sum(os.path.getsize(os.path.join(dp, f)) for dp, _, fns in os.walk(model_path) for f in fns)\n    print(f\"ðŸ’¾ Model size for {target}: {total_size / 1e6:.2f} MB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T19:25:46.136072Z","iopub.execute_input":"2025-07-04T19:25:46.136617Z"}},"outputs":[{"name":"stderr","text":"Verbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.3.1\nPython Version:     3.11.11\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\nCPU Count:          4\nMemory Avail:       29.94 GB / 31.35 GB (95.5%)\nDisk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n===================================================\nPresets specified: ['best_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n\tRunning DyStack for up to 1500s of the 6000s of remaining time (25%).\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ§¹ Clearing old model for: BlendProperty1\n\nðŸš€ Starting training for: BlendProperty1\n","output_type":"stream"},{"name":"stderr","text":"\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n2025-07-04 19:25:48,256\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n\t\tContext path: \"/kaggle/working/autogluon_models/BlendProperty1/ds_sub_fit/sub_fit_ho\"\n\u001b[36m(_dystack pid=3195)\u001b[0m Running DyStack sub-fit ...\n\u001b[36m(_dystack pid=3195)\u001b[0m Beginning AutoGluon training ... Time limit = 1496s\n\u001b[36m(_dystack pid=3195)\u001b[0m AutoGluon will save models to \"/kaggle/working/autogluon_models/BlendProperty1/ds_sub_fit/sub_fit_ho\"\n\u001b[36m(_dystack pid=3195)\u001b[0m Train Data Rows:    1777\n\u001b[36m(_dystack pid=3195)\u001b[0m Train Data Columns: 65\n\u001b[36m(_dystack pid=3195)\u001b[0m Label Column:       BlendProperty1\n\u001b[36m(_dystack pid=3195)\u001b[0m Problem Type:       regression\n\u001b[36m(_dystack pid=3195)\u001b[0m Preprocessing data ...\n\u001b[36m(_dystack pid=3195)\u001b[0m Using Feature Generators to preprocess the data ...\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n\u001b[36m(_dystack pid=3195)\u001b[0m \tAvailable Memory:                    30112.66 MB\n\u001b[36m(_dystack pid=3195)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.88 MB (0.0% of available memory)\n\u001b[36m(_dystack pid=3195)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tStage 1 Generators:\n\u001b[36m(_dystack pid=3195)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n\u001b[36m(_dystack pid=3195)\u001b[0m \tStage 2 Generators:\n\u001b[36m(_dystack pid=3195)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n\u001b[36m(_dystack pid=3195)\u001b[0m \tStage 3 Generators:\n\u001b[36m(_dystack pid=3195)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n\u001b[36m(_dystack pid=3195)\u001b[0m \tStage 4 Generators:\n\u001b[36m(_dystack pid=3195)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n\u001b[36m(_dystack pid=3195)\u001b[0m \tStage 5 Generators:\n\u001b[36m(_dystack pid=3195)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n\u001b[36m(_dystack pid=3195)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n\u001b[36m(_dystack pid=3195)\u001b[0m \t\t('float', []) : 65 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n\u001b[36m(_dystack pid=3195)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n\u001b[36m(_dystack pid=3195)\u001b[0m \t\t('float', []) : 65 | ['Component1_fraction', 'Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component5_fraction', ...]\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.1s = Fit runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t65 features in original data used to generate 65 features in processed data.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.88 MB (0.0% of available memory)\n\u001b[36m(_dystack pid=3195)\u001b[0m Data preprocessing and feature engineering runtime = 0.08s ...\n\u001b[36m(_dystack pid=3195)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'sklearn_safe_mape'\n\u001b[36m(_dystack pid=3195)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n\u001b[36m(_dystack pid=3195)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n\u001b[36m(_dystack pid=3195)\u001b[0m User-specified model hyperparameters to be fit:\n\u001b[36m(_dystack pid=3195)\u001b[0m {\n\u001b[36m(_dystack pid=3195)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n\u001b[36m(_dystack pid=3195)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n\u001b[36m(_dystack pid=3195)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n\u001b[36m(_dystack pid=3195)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n\u001b[36m(_dystack pid=3195)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n\u001b[36m(_dystack pid=3195)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\u001b[36m(_dystack pid=3195)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\u001b[36m(_dystack pid=3195)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n\u001b[36m(_dystack pid=3195)\u001b[0m }\n\u001b[36m(_dystack pid=3195)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 997.18s of the 1496.14s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-2.5395\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.15s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.01s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 997.00s of the 1495.95s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-2.516\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.01s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.01s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 996.96s of the 1495.91s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(_ray_fit pid=3404)\u001b[0m [1000]\tvalid_set's l2: 0.0192157\tvalid_set's sklearn_safe_mape: -0.426266\n\u001b[36m(_ray_fit pid=3547)\u001b[0m [1000]\tvalid_set's l2: 0.0194699\tvalid_set's sklearn_safe_mape: -0.378124\n\u001b[36m(_ray_fit pid=3547)\u001b[0m [2000]\tvalid_set's l2: 0.0194574\tvalid_set's sklearn_safe_mape: -0.378015\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.6407\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t23.25s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.26s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 970.07s of the 1469.02s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.8329\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t15.55s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.04s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 951.29s of the 1450.24s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n\u001b[36m(_dystack pid=3195)\u001b[0m   warnings.warn(\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-1.5563\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t9.01s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.18s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 941.96s of the 1440.91s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.48%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.5509\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t225.5s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.04s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 713.18s of the 1212.14s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n\u001b[36m(_dystack pid=3195)\u001b[0m   warnings.warn(\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-1.3\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t2.32s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.18s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 710.56s of the 1209.52s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n\u001b[36m(_ray_fit pid=4021)\u001b[0m Metric sklearn_safe_mape is not supported by this model - using mean_squared_error instead\n\u001b[36m(_ray_fit pid=4174)\u001b[0m Metric sklearn_safe_mape is not supported by this model - using mean_squared_error instead\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.5629\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t13.83s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.06s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 693.73s of the 1192.68s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.8323\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t20.08s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.04s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 670.45s of the 1169.40s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.6899\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t56.98s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.04s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 610.26s of the 1109.22s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.22%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.8491\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t51.43s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.12s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 555.35s of the 1054.31s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.50%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.4611\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t198.48s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.02s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 353.37s of the 852.33s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.1485\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t66.99s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.04s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 283.29s of the 782.25s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(_ray_fit pid=5178)\u001b[0m [1000]\tvalid_set's l2: 0.0439186\tvalid_set's sklearn_safe_mape: -0.485239\n\u001b[36m(_ray_fit pid=5313)\u001b[0m [1000]\tvalid_set's l2: 0.0402095\tvalid_set's sklearn_safe_mape: -0.456162\n\u001b[36m(_ray_fit pid=5313)\u001b[0m [2000]\tvalid_set's l2: 0.0400914\tvalid_set's sklearn_safe_mape: -0.454674\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.7227\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t35.37s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.24s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 244.02s of the 742.97s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n\u001b[36m(_ray_fit pid=5355)\u001b[0m Metric sklearn_safe_mape is not supported by this model - using mean_squared_error instead\n\u001b[36m(_ray_fit pid=5511)\u001b[0m Metric sklearn_safe_mape is not supported by this model - using mean_squared_error instead\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.5796\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t21.75s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.12s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 219.07s of the 718.02s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.71%)\n\u001b[36m(_ray_fit pid=5552)\u001b[0m \tRan out of time, early stopping on iteration 289.\n\u001b[36m(_ray_fit pid=5718)\u001b[0m \tRan out of time, early stopping on iteration 551.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-1.0256\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t177.08s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.03s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 38.70s of the 537.65s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(_ray_fit pid=5783)\u001b[0m [1000]\tvalid_set's l2: 0.0240631\tvalid_set's sklearn_safe_mape: -0.573081\n\u001b[36m(_ray_fit pid=5782)\u001b[0m [3000]\tvalid_set's l2: 0.0159452\tvalid_set's sklearn_safe_mape: -0.321695\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(_ray_fit pid=5783)\u001b[0m [6000]\tvalid_set's l2: 0.0146756\tvalid_set's sklearn_safe_mape: -0.457242\u001b[32m [repeated 8x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(_ray_fit pid=5783)\u001b[0m \tRan out of time, early stopping on iteration 6660. Best iteration is:\n\u001b[36m(_ray_fit pid=5783)\u001b[0m \t[6186]\tvalid_set's l2: 0.014671\tvalid_set's sklearn_safe_mape: -0.455668\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(_ray_fit pid=5914)\u001b[0m [7000]\tvalid_set's l2: 0.0165498\tvalid_set's sklearn_safe_mape: -0.342526\u001b[32m [repeated 5x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(_ray_fit pid=5914)\u001b[0m \tRan out of time, early stopping on iteration 8554. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(_ray_fit pid=5914)\u001b[0m \t[8550]\tvalid_set's l2: 0.0165147\tvalid_set's sklearn_safe_mape: -0.342092\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.6403\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t25.15s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.9s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 9.41s of the 508.37s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n\u001b[36m(_ray_fit pid=5959)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 13)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.4456\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t14.98s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.04s\t = Validation runtime\n\u001b[36m(_ray_fit pid=5956)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 13)\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 489.75s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 0.875, 'NeuralNetFastAI_BAG_L1': 0.042, 'LightGBM_r96_BAG_L1': 0.042, 'NeuralNetTorch_r22_BAG_L1': 0.042}\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.1414\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.15s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.0s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 489.59s of the 489.55s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(_ray_fit pid=6131)\u001b[0m [1000]\tvalid_set's l2: 0.00632513\tvalid_set's sklearn_safe_mape: -0.205321\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(_ray_fit pid=6264)\u001b[0m [1000]\tvalid_set's l2: 0.0063929\tvalid_set's sklearn_safe_mape: -0.349624\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.3045\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t17.81s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.18s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 468.26s of the 468.22s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n\u001b[36m(_ray_fit pid=6090)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 31)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(_ray_fit pid=6440)\u001b[0m [1000]\tvalid_set's l2: 0.00423885\tvalid_set's sklearn_safe_mape: -0.206158\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.1624\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t23.18s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.1s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 441.76s of the 441.71s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n\u001b[36m(_dystack pid=3195)\u001b[0m   warnings.warn(\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.1507\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t10.47s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.18s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 430.99s of the 430.95s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.54%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.2822\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t132.24s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.04s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 295.68s of the 295.64s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n\u001b[36m(_dystack pid=3195)\u001b[0m   warnings.warn(\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.202\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t2.75s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.18s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 292.63s of the 292.59s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n\u001b[36m(_ray_fit pid=6721)\u001b[0m Metric sklearn_safe_mape is not supported by this model - using mean_squared_error instead\n\u001b[36m(_ray_fit pid=6873)\u001b[0m Metric sklearn_safe_mape is not supported by this model - using mean_squared_error instead\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.4667\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t14.2s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.11s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 275.38s of the 275.34s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.14%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.1771\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t19.64s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.07s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 252.40s of the 252.35s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t-0.3698\t = Validation score   (-sklearn_safe_mape)\n\u001b[36m(_dystack pid=3195)\u001b[0m \t28.67s\t = Training   runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m \t0.04s\t = Validation runtime\n\u001b[36m(_dystack pid=3195)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 220.42s of the 220.38s of remaining time.\n\u001b[36m(_dystack pid=3195)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.28%)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}